{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54a92b98",
   "metadata": {},
   "source": [
    "## Separación en train y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd7cdb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (5220, 14)\n",
      "Val shape: (580, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\34629\\AppData\\Local\\Temp\\ipykernel_19204\\2436709630.py:22: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(frac=0.10, random_state=42))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset original (sin imágenes aumentadas)\n",
    "original_df = pd.read_csv(\"C:/Users/34629/TFG/single_label_dataset_without_H_no_O.csv\")\n",
    "\n",
    "# Definir las clases\n",
    "classes = ['N', 'D', 'G', 'C', 'A', 'M']\n",
    "\n",
    "# Añadir columna de clase dominante\n",
    "def get_class_label(row):\n",
    "    for c in classes:\n",
    "        if row[c] == 1:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "original_df['class_label'] = original_df.apply(get_class_label, axis=1)\n",
    "\n",
    "# Dividir: 10% validación por clase\n",
    "val_df = (\n",
    "    original_df\n",
    "    .groupby('class_label', group_keys=False)\n",
    "    .apply(lambda x: x.sample(frac=0.10, random_state=42))\n",
    ")\n",
    "\n",
    "# Entrenamiento: el resto\n",
    "train_df = original_df[~original_df['Image_Path'].isin(val_df['Image_Path'])]\n",
    "\n",
    "# Guardar CSVs\n",
    "train_path = \"C:/Users/34629/TFG/train_DES.csv\"\n",
    "val_path   = \"C:/Users/34629/TFG/val_DES.csv\"\n",
    "train_df.to_csv(train_path, index=False)\n",
    "val_df.to_csv(val_path, index=False)\n",
    "\n",
    "# Confirmar resultados\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Val shape:\", val_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be3685a",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94659708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Features cargadas desde disco.\n",
      "✅ Validación cargada.\n",
      "Epoch 1/80\n",
      "WARNING:tensorflow:From c:\\Users\\34629\\TFG\\env\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "327/327 - 10s - loss: 1.9708 - accuracy: 0.4626 - f1: 0.1711 - val_loss: 1.6452 - val_accuracy: 0.5345 - val_f1: 0.1161 - 10s/epoch - 30ms/step\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\34629\\TFG\\env\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327/327 - 8s - loss: 1.4526 - accuracy: 0.4847 - f1: 0.2100 - val_loss: 1.2422 - val_accuracy: 0.5483 - val_f1: 0.1933 - 8s/epoch - 24ms/step\n",
      "Epoch 3/80\n",
      "327/327 - 9s - loss: 1.1480 - accuracy: 0.4960 - f1: 0.2811 - val_loss: 1.0051 - val_accuracy: 0.5603 - val_f1: 0.3908 - 9s/epoch - 26ms/step\n",
      "Epoch 4/80\n",
      "327/327 - 8s - loss: 0.9516 - accuracy: 0.5167 - f1: 0.3319 - val_loss: 0.8496 - val_accuracy: 0.5741 - val_f1: 0.3465 - 8s/epoch - 26ms/step\n",
      "Epoch 5/80\n",
      "327/327 - 9s - loss: 0.8161 - accuracy: 0.5420 - f1: 0.3720 - val_loss: 0.7423 - val_accuracy: 0.5603 - val_f1: 0.4013 - 9s/epoch - 27ms/step\n",
      "Epoch 6/80\n",
      "327/327 - 8s - loss: 0.7115 - accuracy: 0.5448 - f1: 0.3868 - val_loss: 0.6603 - val_accuracy: 0.5793 - val_f1: 0.3192 - 8s/epoch - 24ms/step\n",
      "Epoch 7/80\n",
      "327/327 - 9s - loss: 0.6292 - accuracy: 0.5466 - f1: 0.3892 - val_loss: 0.5758 - val_accuracy: 0.5655 - val_f1: 0.4140 - 9s/epoch - 27ms/step\n",
      "Epoch 8/80\n",
      "327/327 - 9s - loss: 0.5595 - accuracy: 0.5563 - f1: 0.3990 - val_loss: 0.5249 - val_accuracy: 0.5345 - val_f1: 0.3927 - 9s/epoch - 27ms/step\n",
      "Epoch 9/80\n",
      "327/327 - 8s - loss: 0.5047 - accuracy: 0.5433 - f1: 0.3921 - val_loss: 0.4625 - val_accuracy: 0.5931 - val_f1: 0.3769 - 8s/epoch - 24ms/step\n",
      "Epoch 10/80\n",
      "327/327 - 8s - loss: 0.4582 - accuracy: 0.5623 - f1: 0.4053 - val_loss: 0.4227 - val_accuracy: 0.5776 - val_f1: 0.4141 - 8s/epoch - 23ms/step\n",
      "Epoch 11/80\n",
      "327/327 - 7s - loss: 0.4154 - accuracy: 0.5738 - f1: 0.4098 - val_loss: 0.3816 - val_accuracy: 0.5879 - val_f1: 0.3681 - 7s/epoch - 22ms/step\n",
      "Epoch 12/80\n",
      "327/327 - 8s - loss: 0.3810 - accuracy: 0.5634 - f1: 0.4034 - val_loss: 0.3536 - val_accuracy: 0.5552 - val_f1: 0.4255 - 8s/epoch - 24ms/step\n",
      "Epoch 13/80\n",
      "327/327 - 8s - loss: 0.3511 - accuracy: 0.5684 - f1: 0.4065 - val_loss: 0.3261 - val_accuracy: 0.5638 - val_f1: 0.4237 - 8s/epoch - 24ms/step\n",
      "Epoch 14/80\n",
      "327/327 - 8s - loss: 0.3244 - accuracy: 0.5762 - f1: 0.4178 - val_loss: 0.3013 - val_accuracy: 0.5862 - val_f1: 0.3935 - 8s/epoch - 24ms/step\n",
      "Epoch 15/80\n",
      "327/327 - 8s - loss: 0.3015 - accuracy: 0.5778 - f1: 0.4185 - val_loss: 0.2841 - val_accuracy: 0.5879 - val_f1: 0.4332 - 8s/epoch - 24ms/step\n",
      "Epoch 16/80\n",
      "327/327 - 8s - loss: 0.2833 - accuracy: 0.5830 - f1: 0.4173 - val_loss: 0.2670 - val_accuracy: 0.5879 - val_f1: 0.3730 - 8s/epoch - 24ms/step\n",
      "Epoch 17/80\n",
      "327/327 - 8s - loss: 0.2702 - accuracy: 0.5738 - f1: 0.4105 - val_loss: 0.2521 - val_accuracy: 0.5845 - val_f1: 0.3839 - 8s/epoch - 26ms/step\n",
      "Epoch 18/80\n",
      "327/327 - 9s - loss: 0.2517 - accuracy: 0.5824 - f1: 0.4194 - val_loss: 0.2347 - val_accuracy: 0.5966 - val_f1: 0.3774 - 9s/epoch - 27ms/step\n",
      "Epoch 19/80\n",
      "327/327 - 9s - loss: 0.2400 - accuracy: 0.5835 - f1: 0.4226 - val_loss: 0.2250 - val_accuracy: 0.5914 - val_f1: 0.3584 - 9s/epoch - 26ms/step\n",
      "Epoch 20/80\n",
      "327/327 - 8s - loss: 0.2278 - accuracy: 0.5764 - f1: 0.4195 - val_loss: 0.2154 - val_accuracy: 0.5879 - val_f1: 0.4310 - 8s/epoch - 23ms/step\n",
      "Epoch 21/80\n",
      "327/327 - 7s - loss: 0.2211 - accuracy: 0.5751 - f1: 0.4050 - val_loss: 0.2082 - val_accuracy: 0.5897 - val_f1: 0.4139 - 7s/epoch - 22ms/step\n",
      "Epoch 22/80\n",
      "327/327 - 7s - loss: 0.2124 - accuracy: 0.5715 - f1: 0.4066 - val_loss: 0.1984 - val_accuracy: 0.5914 - val_f1: 0.3769 - 7s/epoch - 22ms/step\n",
      "Epoch 23/80\n",
      "327/327 - 7s - loss: 0.2034 - accuracy: 0.5820 - f1: 0.4190 - val_loss: 0.1940 - val_accuracy: 0.5983 - val_f1: 0.4249 - 7s/epoch - 23ms/step\n",
      "Epoch 24/80\n",
      "327/327 - 7s - loss: 0.1964 - accuracy: 0.5891 - f1: 0.4252 - val_loss: 0.1891 - val_accuracy: 0.5897 - val_f1: 0.3794 - 7s/epoch - 22ms/step\n",
      "Epoch 25/80\n",
      "327/327 - 7s - loss: 0.1926 - accuracy: 0.5902 - f1: 0.4194 - val_loss: 0.1787 - val_accuracy: 0.5966 - val_f1: 0.3886 - 7s/epoch - 22ms/step\n",
      "Epoch 26/80\n",
      "327/327 - 7s - loss: 0.1841 - accuracy: 0.5918 - f1: 0.4306 - val_loss: 0.1845 - val_accuracy: 0.5793 - val_f1: 0.3429 - 7s/epoch - 22ms/step\n",
      "Epoch 27/80\n",
      "327/327 - 7s - loss: 0.1821 - accuracy: 0.5893 - f1: 0.4110 - val_loss: 0.1687 - val_accuracy: 0.5862 - val_f1: 0.4774 - 7s/epoch - 23ms/step\n",
      "Epoch 28/80\n",
      "327/327 - 7s - loss: 0.1764 - accuracy: 0.5866 - f1: 0.4160 - val_loss: 0.1630 - val_accuracy: 0.5983 - val_f1: 0.4121 - 7s/epoch - 22ms/step\n",
      "Epoch 29/80\n",
      "327/327 - 7s - loss: 0.1750 - accuracy: 0.5856 - f1: 0.4109 - val_loss: 0.1614 - val_accuracy: 0.6034 - val_f1: 0.4647 - 7s/epoch - 22ms/step\n",
      "Epoch 30/80\n",
      "327/327 - 7s - loss: 0.1692 - accuracy: 0.5918 - f1: 0.4260 - val_loss: 0.1590 - val_accuracy: 0.5931 - val_f1: 0.4353 - 7s/epoch - 23ms/step\n",
      "Epoch 31/80\n",
      "327/327 - 7s - loss: 0.1674 - accuracy: 0.5904 - f1: 0.4138 - val_loss: 0.1676 - val_accuracy: 0.5828 - val_f1: 0.3244 - 7s/epoch - 22ms/step\n",
      "Epoch 32/80\n",
      "327/327 - 7s - loss: 0.1621 - accuracy: 0.5958 - f1: 0.4209 - val_loss: 0.1612 - val_accuracy: 0.5810 - val_f1: 0.3848 - 7s/epoch - 22ms/step\n",
      "Epoch 33/80\n",
      "327/327 - 7s - loss: 0.1611 - accuracy: 0.5996 - f1: 0.4218 - val_loss: 0.1533 - val_accuracy: 0.5862 - val_f1: 0.3708 - 7s/epoch - 22ms/step\n",
      "Epoch 34/80\n",
      "327/327 - 7s - loss: 0.1590 - accuracy: 0.5954 - f1: 0.4243 - val_loss: 0.1526 - val_accuracy: 0.5879 - val_f1: 0.3565 - 7s/epoch - 22ms/step\n",
      "Epoch 35/80\n",
      "327/327 - 7s - loss: 0.1576 - accuracy: 0.5939 - f1: 0.4207 - val_loss: 0.1545 - val_accuracy: 0.6000 - val_f1: 0.3818 - 7s/epoch - 22ms/step\n",
      "Epoch 36/80\n",
      "327/327 - 7s - loss: 0.1575 - accuracy: 0.5874 - f1: 0.4117 - val_loss: 0.1469 - val_accuracy: 0.5897 - val_f1: 0.3740 - 7s/epoch - 22ms/step\n",
      "Epoch 37/80\n",
      "327/327 - 7s - loss: 0.1548 - accuracy: 0.5939 - f1: 0.4199 - val_loss: 0.1440 - val_accuracy: 0.6069 - val_f1: 0.4608 - 7s/epoch - 22ms/step\n",
      "Epoch 38/80\n",
      "327/327 - 7s - loss: 0.1512 - accuracy: 0.6065 - f1: 0.4361 - val_loss: 0.1471 - val_accuracy: 0.5793 - val_f1: 0.4239 - 7s/epoch - 23ms/step\n",
      "Epoch 39/80\n",
      "327/327 - 7s - loss: 0.1516 - accuracy: 0.5985 - f1: 0.4204 - val_loss: 0.1466 - val_accuracy: 0.5759 - val_f1: 0.4354 - 7s/epoch - 23ms/step\n",
      "Epoch 40/80\n",
      "327/327 - 8s - loss: 0.1499 - accuracy: 0.5948 - f1: 0.4237 - val_loss: 0.1477 - val_accuracy: 0.5879 - val_f1: 0.3635 - 8s/epoch - 23ms/step\n",
      "Epoch 41/80\n",
      "327/327 - 8s - loss: 0.1496 - accuracy: 0.5900 - f1: 0.4121 - val_loss: 0.1441 - val_accuracy: 0.5897 - val_f1: 0.3561 - 8s/epoch - 23ms/step\n",
      "Epoch 42/80\n",
      "327/327 - 7s - loss: 0.1473 - accuracy: 0.5964 - f1: 0.4216 - val_loss: 0.1398 - val_accuracy: 0.5931 - val_f1: 0.4256 - 7s/epoch - 22ms/step\n",
      "Epoch 43/80\n",
      "327/327 - 7s - loss: 0.1476 - accuracy: 0.5998 - f1: 0.4230 - val_loss: 0.1398 - val_accuracy: 0.5983 - val_f1: 0.4098 - 7s/epoch - 23ms/step\n",
      "Epoch 44/80\n",
      "327/327 - 7s - loss: 0.1449 - accuracy: 0.5966 - f1: 0.4219 - val_loss: 0.1361 - val_accuracy: 0.5914 - val_f1: 0.4460 - 7s/epoch - 22ms/step\n",
      "Epoch 45/80\n",
      "327/327 - 7s - loss: 0.1438 - accuracy: 0.5994 - f1: 0.4245 - val_loss: 0.1361 - val_accuracy: 0.5879 - val_f1: 0.3884 - 7s/epoch - 22ms/step\n",
      "Epoch 46/80\n",
      "327/327 - 7s - loss: 0.1428 - accuracy: 0.5973 - f1: 0.4199 - val_loss: 0.1422 - val_accuracy: 0.5776 - val_f1: 0.4005 - 7s/epoch - 22ms/step\n",
      "Epoch 47/80\n",
      "327/327 - 8s - loss: 0.1435 - accuracy: 0.5981 - f1: 0.4202 - val_loss: 0.1406 - val_accuracy: 0.5862 - val_f1: 0.4267 - 8s/epoch - 23ms/step\n",
      "Epoch 48/80\n",
      "327/327 - 8s - loss: 0.1432 - accuracy: 0.5925 - f1: 0.4158 - val_loss: 0.1343 - val_accuracy: 0.6034 - val_f1: 0.4370 - 8s/epoch - 23ms/step\n",
      "Epoch 49/80\n",
      "327/327 - 7s - loss: 0.1407 - accuracy: 0.5975 - f1: 0.4204 - val_loss: 0.1344 - val_accuracy: 0.6069 - val_f1: 0.4049 - 7s/epoch - 23ms/step\n",
      "Epoch 50/80\n",
      "327/327 - 8s - loss: 0.1410 - accuracy: 0.5981 - f1: 0.4218 - val_loss: 0.1353 - val_accuracy: 0.6034 - val_f1: 0.4412 - 8s/epoch - 23ms/step\n",
      "Epoch 51/80\n",
      "327/327 - 8s - loss: 0.1419 - accuracy: 0.5994 - f1: 0.4192 - val_loss: 0.1333 - val_accuracy: 0.5879 - val_f1: 0.3762 - 8s/epoch - 23ms/step\n",
      "Epoch 52/80\n",
      "327/327 - 8s - loss: 0.1387 - accuracy: 0.6038 - f1: 0.4329 - val_loss: 0.1288 - val_accuracy: 0.6017 - val_f1: 0.3971 - 8s/epoch - 24ms/step\n",
      "Epoch 53/80\n",
      "327/327 - 9s - loss: 0.1391 - accuracy: 0.5996 - f1: 0.4202 - val_loss: 0.1326 - val_accuracy: 0.5931 - val_f1: 0.4216 - 9s/epoch - 27ms/step\n",
      "Epoch 54/80\n",
      "327/327 - 8s - loss: 0.1373 - accuracy: 0.5987 - f1: 0.4213 - val_loss: 0.1319 - val_accuracy: 0.5690 - val_f1: 0.4221 - 8s/epoch - 25ms/step\n",
      "Epoch 55/80\n",
      "327/327 - 9s - loss: 0.1375 - accuracy: 0.5987 - f1: 0.4202 - val_loss: 0.1345 - val_accuracy: 0.5914 - val_f1: 0.3607 - 9s/epoch - 27ms/step\n",
      "Epoch 56/80\n",
      "327/327 - 9s - loss: 0.1364 - accuracy: 0.6100 - f1: 0.4225 - val_loss: 0.1292 - val_accuracy: 0.5793 - val_f1: 0.4068 - 9s/epoch - 26ms/step\n",
      "Epoch 57/80\n",
      "327/327 - 8s - loss: 0.1370 - accuracy: 0.5946 - f1: 0.4280 - val_loss: 0.1285 - val_accuracy: 0.5983 - val_f1: 0.3853 - 8s/epoch - 24ms/step\n",
      "Epoch 58/80\n",
      "327/327 - 7s - loss: 0.1367 - accuracy: 0.5967 - f1: 0.4211 - val_loss: 0.1298 - val_accuracy: 0.5914 - val_f1: 0.3946 - 7s/epoch - 23ms/step\n",
      "Epoch 59/80\n",
      "327/327 - 7s - loss: 0.1359 - accuracy: 0.5998 - f1: 0.4265 - val_loss: 0.1351 - val_accuracy: 0.5828 - val_f1: 0.3802 - 7s/epoch - 21ms/step\n",
      "Epoch 60/80\n",
      "327/327 - 7s - loss: 0.1345 - accuracy: 0.6021 - f1: 0.4261 - val_loss: 0.1265 - val_accuracy: 0.5914 - val_f1: 0.4025 - 7s/epoch - 22ms/step\n",
      "Epoch 61/80\n",
      "327/327 - 7s - loss: 0.1348 - accuracy: 0.5958 - f1: 0.4238 - val_loss: 0.1263 - val_accuracy: 0.6121 - val_f1: 0.4581 - 7s/epoch - 22ms/step\n",
      "Epoch 62/80\n",
      "327/327 - 7s - loss: 0.1368 - accuracy: 0.5962 - f1: 0.4208 - val_loss: 0.1258 - val_accuracy: 0.5983 - val_f1: 0.4143 - 7s/epoch - 21ms/step\n",
      "Epoch 63/80\n",
      "327/327 - 7s - loss: 0.1358 - accuracy: 0.5971 - f1: 0.4220 - val_loss: 0.1320 - val_accuracy: 0.5724 - val_f1: 0.4326 - 7s/epoch - 22ms/step\n",
      "Epoch 64/80\n",
      "327/327 - 7s - loss: 0.1342 - accuracy: 0.6002 - f1: 0.4257 - val_loss: 0.1255 - val_accuracy: 0.6034 - val_f1: 0.4095 - 7s/epoch - 22ms/step\n",
      "Epoch 65/80\n",
      "327/327 - 7s - loss: 0.1351 - accuracy: 0.5956 - f1: 0.4183 - val_loss: 0.1332 - val_accuracy: 0.5966 - val_f1: 0.3678 - 7s/epoch - 22ms/step\n",
      "Epoch 66/80\n",
      "327/327 - 7s - loss: 0.1338 - accuracy: 0.5992 - f1: 0.4202 - val_loss: 0.1261 - val_accuracy: 0.6121 - val_f1: 0.4573 - 7s/epoch - 23ms/step\n",
      "Epoch 67/80\n",
      "327/327 - 7s - loss: 0.1344 - accuracy: 0.5927 - f1: 0.4176 - val_loss: 0.1241 - val_accuracy: 0.6000 - val_f1: 0.4210 - 7s/epoch - 22ms/step\n",
      "Epoch 68/80\n",
      "327/327 - 7s - loss: 0.1325 - accuracy: 0.6086 - f1: 0.4324 - val_loss: 0.1298 - val_accuracy: 0.5983 - val_f1: 0.4059 - 7s/epoch - 22ms/step\n",
      "Epoch 69/80\n",
      "327/327 - 7s - loss: 0.1314 - accuracy: 0.6033 - f1: 0.4325 - val_loss: 0.1361 - val_accuracy: 0.5931 - val_f1: 0.3824 - 7s/epoch - 22ms/step\n",
      "Epoch 70/80\n",
      "327/327 - 7s - loss: 0.1327 - accuracy: 0.5969 - f1: 0.4209 - val_loss: 0.1298 - val_accuracy: 0.5914 - val_f1: 0.4130 - 7s/epoch - 21ms/step\n",
      "Epoch 71/80\n",
      "327/327 - 7s - loss: 0.1339 - accuracy: 0.5998 - f1: 0.4235 - val_loss: 0.1247 - val_accuracy: 0.5914 - val_f1: 0.4140 - 7s/epoch - 21ms/step\n",
      "Epoch 72/80\n",
      "327/327 - 7s - loss: 0.1330 - accuracy: 0.5985 - f1: 0.4241 - val_loss: 0.1282 - val_accuracy: 0.5983 - val_f1: 0.4277 - 7s/epoch - 21ms/step\n",
      "Epoch 73/80\n",
      "327/327 - 7s - loss: 0.1328 - accuracy: 0.5987 - f1: 0.4225 - val_loss: 0.1280 - val_accuracy: 0.5862 - val_f1: 0.4015 - 7s/epoch - 22ms/step\n",
      "Epoch 74/80\n",
      "327/327 - 7s - loss: 0.1315 - accuracy: 0.5975 - f1: 0.4250 - val_loss: 0.1234 - val_accuracy: 0.5793 - val_f1: 0.4561 - 7s/epoch - 21ms/step\n",
      "Epoch 75/80\n",
      "327/327 - 7s - loss: 0.1323 - accuracy: 0.6008 - f1: 0.4245 - val_loss: 0.1308 - val_accuracy: 0.5948 - val_f1: 0.4013 - 7s/epoch - 21ms/step\n",
      "Epoch 76/80\n",
      "327/327 - 7s - loss: 0.1330 - accuracy: 0.5994 - f1: 0.4236 - val_loss: 0.1249 - val_accuracy: 0.6103 - val_f1: 0.4539 - 7s/epoch - 22ms/step\n",
      "Epoch 77/80\n",
      "327/327 - 7s - loss: 0.1309 - accuracy: 0.5975 - f1: 0.4190 - val_loss: 0.1239 - val_accuracy: 0.6052 - val_f1: 0.4164 - 7s/epoch - 21ms/step\n",
      "Epoch 78/80\n",
      "327/327 - 7s - loss: 0.1310 - accuracy: 0.5937 - f1: 0.4230 - val_loss: 0.1385 - val_accuracy: 0.5948 - val_f1: 0.3809 - 7s/epoch - 22ms/step\n",
      "Epoch 79/80\n",
      "327/327 - 7s - loss: 0.1333 - accuracy: 0.5987 - f1: 0.4184 - val_loss: 0.1250 - val_accuracy: 0.6034 - val_f1: 0.4006 - 7s/epoch - 21ms/step\n",
      "Epoch 80/80\n",
      "327/327 - 7s - loss: 0.1305 - accuracy: 0.6027 - f1: 0.4312 - val_loss: 0.1262 - val_accuracy: 0.5845 - val_f1: 0.4312 - 7s/epoch - 21ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.62      0.73      0.67       310\n",
      "           D       0.46      0.41      0.44       167\n",
      "           G       0.00      0.00      0.00        26\n",
      "           C       0.74      0.69      0.71        29\n",
      "           A       0.00      0.00      0.00        24\n",
      "           M       0.64      0.96      0.77        24\n",
      "\n",
      "    accuracy                           0.58       580\n",
      "   macro avg       0.41      0.47      0.43       580\n",
      "weighted avg       0.53      0.58      0.55       580\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\34629\\TFG\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\34629\\TFG\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\34629\\TFG\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "### Modelo 1 - Dataset desbalanceado ###\n",
    "\n",
    "import os, sys, cv2, torch, argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Config\n",
    "IMG_SIZE   = 224\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS     = 80\n",
    "LABELS     = ['N', 'D', 'G', 'C', 'A', 'M']\n",
    "LABEL_MAP  = {c: i for i, c in enumerate(LABELS)}\n",
    "\n",
    "# Dataset\n",
    "csv_path = \"C:/Users/34629/TFG/train_DES.csv\"\n",
    "paths = pd.read_csv(csv_path)\n",
    "paths[\"class_label\"] = paths[LABELS].idxmax(axis=1)\n",
    "paths[\"label\"] = paths[\"class_label\"].map(LABEL_MAP)\n",
    "\n",
    "image_paths = paths[\"Image_Path\"].tolist()\n",
    "y = paths[\"label\"].values\n",
    "\n",
    "# Comprobación previa de features\n",
    "rf_path = \"C:/Users/34629/Downloads/X_rf_train_DES.npy\"\n",
    "y_path  = \"C:/Users/34629/Downloads/y_train_DES.npy\"\n",
    "\n",
    "if os.path.exists(rf_path) and os.path.exists(y_path):\n",
    "    X_rf = np.load(rf_path)\n",
    "    y = np.load(y_path)\n",
    "    print(\"✅ Features cargadas desde disco.\")\n",
    "else:\n",
    "    sys.path.append(r\"C:/Users/34629/Downloads/RETFound_MAE\")\n",
    "    from models_vit import RETFound_mae\n",
    "    from util.pos_embed import interpolate_pos_embed\n",
    "    torch.serialization.add_safe_globals([argparse.Namespace])\n",
    "\n",
    "    def extract_features(img_paths, weights_path):\n",
    "        model = RETFound_mae(global_pool=True, img_size=IMG_SIZE)\n",
    "        ckpt = torch.load(weights_path, map_location='cpu', weights_only=False)\n",
    "        sd = ckpt['model']\n",
    "        sd.pop('head.weight', None)\n",
    "        sd.pop('head.bias', None)\n",
    "        interpolate_pos_embed(model, sd)\n",
    "        model.load_state_dict(sd, strict=False)\n",
    "        model.eval()\n",
    "\n",
    "        feats = []\n",
    "        for p in tqdm(img_paths, desc=\"Extrayendo RETFound\"):\n",
    "            img = cv2.resize(cv2.imread(p), (IMG_SIZE, IMG_SIZE)) / 255.0\n",
    "            x = torch.from_numpy(img.astype('float32')).permute(2,0,1).unsqueeze(0)\n",
    "            with torch.no_grad():\n",
    "                f = model.forward_features(x).cpu().numpy().squeeze()\n",
    "            feats.append(f)\n",
    "        return np.stack(feats)\n",
    "\n",
    "    X_rf = extract_features(image_paths, \"C:/Users/34629/Downloads/RETFound_MAE/RETFound_cfp_weights.pth\")\n",
    "    np.save(rf_path, X_rf)\n",
    "    np.save(y_path, y)\n",
    "\n",
    "# Validación separada\n",
    "val_csv = pd.read_csv(\"C:/Users/34629/TFG/val_DES.csv\")\n",
    "val_csv[\"class_label\"] = val_csv[LABELS].idxmax(axis=1)\n",
    "val_csv[\"label\"] = val_csv[\"class_label\"].map(LABEL_MAP)\n",
    "val_paths = val_csv[\"Image_Path\"].tolist()\n",
    "y_val = val_csv[\"label\"].values\n",
    "\n",
    "# Cargar features validación\n",
    "X_rf_val_path = \"C:/Users/34629/Downloads/X_rf_val_DES.npy\"\n",
    "y_val_path    = \"C:/Users/34629/Downloads/y_val_DES.npy\"\n",
    "\n",
    "if os.path.exists(X_rf_val_path) and os.path.exists(y_val_path):\n",
    "    X_vl = np.load(X_rf_val_path)\n",
    "    y_val = np.load(y_val_path)\n",
    "    print(\"✅ Validación cargada.\")\n",
    "else:\n",
    "    X_vl = extract_features(val_paths, \"C:/Users/34629/Downloads/RETFound_MAE/RETFound_cfp_weights.pth\")\n",
    "    np.save(X_rf_val_path, X_vl)\n",
    "    np.save(y_val_path, y_val)\n",
    "\n",
    "# One-hot\n",
    "y_tr_cat = to_categorical(y, num_classes=len(LABELS))\n",
    "y_vl_cat = to_categorical(y_val, num_classes=len(LABELS))\n",
    "\n",
    "# Modelo\n",
    "\n",
    "def categorical_focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def loss(y_true, y_pred):\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
    "        return K.sum(loss, axis=-1)\n",
    "    return loss\n",
    "\n",
    "inp = Input((X_rf.shape[1],))\n",
    "x = Dense(1024, kernel_regularizer=tf.keras.regularizers.l2(1e-3))(inp)\n",
    "x = LayerNormalization()(x)\n",
    "x = LeakyReLU(0.1)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(512, kernel_regularizer=tf.keras.regularizers.l2(1e-3))(x)\n",
    "x = LayerNormalization()(x)\n",
    "x = LeakyReLU(0.1)(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "x = Dense(256, kernel_regularizer=tf.keras.regularizers.l2(1e-3))(x)\n",
    "x = LayerNormalization()(x)\n",
    "x = LeakyReLU(0.1)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "out = Dense(len(LABELS), activation='softmax')(x)\n",
    "m = Model(inp, out)\n",
    "\n",
    "loss_fn = categorical_focal_loss(gamma=2.0, alpha=0.25)\n",
    "m.compile(optimizer=Adam(1e-4), loss=loss_fn,\n",
    "          metrics=['accuracy', tfa.metrics.F1Score(num_classes=len(LABELS), average='macro', name='f1')])\n",
    "\n",
    "cb = [\n",
    "    EarlyStopping('val_f1', mode='max', patience=60, restore_best_weights=True),\n",
    "    ModelCheckpoint(\"modelo1_DESB.h5\", monitor='val_f1', mode='max', save_best_only=True)\n",
    "]\n",
    "\n",
    "m.fit(X_rf, y_tr_cat, validation_data=(X_vl, y_vl_cat),\n",
    "      epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=cb, verbose=2)\n",
    "\n",
    "# Inference\n",
    "probs = m.predict(X_vl)\n",
    "y_pred = probs.argmax(axis=1)\n",
    "\n",
    "print(classification_report(y_val, y_pred, target_names=LABELS))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=LABELS, yticklabels=LABELS)\n",
    "plt.title(\"Matriz de Confusión - Modelo 1 DESB\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"confusion_matrix_modelo1_DES.png\")\n",
    "plt.close()\n",
    "\n",
    "# ROC\n",
    "y_val_bin = label_binarize(y_val, classes=np.arange(len(LABELS)))\n",
    "plt.figure(figsize=(10, 7))\n",
    "for i in range(len(LABELS)):\n",
    "    fpr, tpr, _ = roc_curve(y_val_bin[:, i], probs[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'{LABELS[i]} (AUC={roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title(\"Curvas ROC - Modelo 1 DESB\")\n",
    "plt.legend(); plt.tight_layout()\n",
    "plt.savefig(\"curvas_ROC_modelo1_DES.png\")\n",
    "plt.close()\n",
    "\n",
    "# Grad-CAM\n",
    "def generar_gradcam(img_path, nombre_archivo):\n",
    "    model = RETFound_mae(global_pool=False, img_size=IMG_SIZE)\n",
    "    ckpt = torch.load(\"C:/Users/34629/Downloads/RETFound_MAE/RETFound_cfp_weights.pth\", map_location='cpu')\n",
    "    sd = ckpt['model']\n",
    "    sd.pop('head.weight', None); sd.pop('head.bias', None)\n",
    "    interpolate_pos_embed(model, sd)\n",
    "    model.load_state_dict(sd, strict=False); model.eval()\n",
    "    activations = {}\n",
    "    model.blocks[11].register_forward_hook(lambda m, i, o: activations.update({'value': o}))\n",
    "    img = Image.open(img_path).convert('RGB').resize((IMG_SIZE, IMG_SIZE))\n",
    "    x = transforms.ToTensor()(img).unsqueeze(0)\n",
    "    with torch.no_grad(): model(x)\n",
    "    cam = activations['value'].squeeze(0).numpy()[1:].mean(axis=1).reshape(14, 14)\n",
    "    cam = cv2.resize((cam - cam.min()) / (cam.max() - cam.min()), (IMG_SIZE, IMG_SIZE))\n",
    "    cam = np.uint8(255 * cam)\n",
    "    cam_color = cv2.applyColorMap(cam, cv2.COLORMAP_JET)\n",
    "    superpuesta = 0.4 * np.array(img) + 0.6 * cam_color\n",
    "    cv2.imwrite(nombre_archivo, cv2.cvtColor(np.uint8(superpuesta), cv2.COLOR_RGB2BGR))\n",
    "\n",
    "df_res = pd.DataFrame({\n",
    "    \"img\": val_paths,\n",
    "    \"true\": [LABELS[i] for i in y_val],\n",
    "    \"pred\": [LABELS[i] for i in y_pred]\n",
    "})\n",
    "df_res[\"correct\"] = df_res[\"true\"] == df_res[\"pred\"]\n",
    "\n",
    "bien = df_res[df_res[\"correct\"]].iloc[0]\n",
    "mal = df_res[~df_res[\"correct\"]].iloc[0]\n",
    "generar_gradcam(bien[\"img\"], f\"gradcam_modelo1_DES_correcto_{bien['true']}.png\")\n",
    "generar_gradcam(mal[\"img\"], f\"gradcam_modelo1_DES_error_{mal['true']}_pred{mal['pred']}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75063e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RETFound cargado de disco.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EffNet feats: 100%|██████████| 5220/5220 [33:21<00:00,  2.61it/s]  \n",
      "EffNet feats: 100%|██████████| 580/580 [03:30<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "327/327 - 8s - loss: 0.3126 - accuracy: 0.4161 - f1: 0.1770 - val_loss: 0.2166 - val_accuracy: 0.5379 - val_f1: 0.1295 - 8s/epoch - 25ms/step\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\34629\\TFG\\env\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327/327 - 6s - loss: 0.2521 - accuracy: 0.4728 - f1: 0.1930 - val_loss: 0.2084 - val_accuracy: 0.5397 - val_f1: 0.1418 - 6s/epoch - 19ms/step\n",
      "Epoch 3/80\n",
      "327/327 - 6s - loss: 0.2330 - accuracy: 0.4927 - f1: 0.2232 - val_loss: 0.1993 - val_accuracy: 0.5310 - val_f1: 0.2767 - 6s/epoch - 19ms/step\n",
      "Epoch 4/80\n",
      "327/327 - 6s - loss: 0.2176 - accuracy: 0.5125 - f1: 0.2758 - val_loss: 0.1910 - val_accuracy: 0.5534 - val_f1: 0.2587 - 6s/epoch - 19ms/step\n",
      "Epoch 5/80\n",
      "327/327 - 6s - loss: 0.2063 - accuracy: 0.5289 - f1: 0.3278 - val_loss: 0.1852 - val_accuracy: 0.5586 - val_f1: 0.3556 - 6s/epoch - 19ms/step\n",
      "Epoch 6/80\n",
      "327/327 - 6s - loss: 0.2000 - accuracy: 0.5500 - f1: 0.3610 - val_loss: 0.1813 - val_accuracy: 0.5724 - val_f1: 0.3856 - 6s/epoch - 19ms/step\n",
      "Epoch 7/80\n",
      "327/327 - 6s - loss: 0.1943 - accuracy: 0.5594 - f1: 0.3865 - val_loss: 0.1779 - val_accuracy: 0.5759 - val_f1: 0.4265 - 6s/epoch - 19ms/step\n",
      "Epoch 8/80\n",
      "327/327 - 6s - loss: 0.1890 - accuracy: 0.5718 - f1: 0.4050 - val_loss: 0.1771 - val_accuracy: 0.5569 - val_f1: 0.4205 - 6s/epoch - 19ms/step\n",
      "Epoch 9/80\n",
      "327/327 - 6s - loss: 0.1865 - accuracy: 0.5665 - f1: 0.4108 - val_loss: 0.1768 - val_accuracy: 0.5897 - val_f1: 0.3800 - 6s/epoch - 19ms/step\n",
      "Epoch 10/80\n",
      "327/327 - 6s - loss: 0.1866 - accuracy: 0.5638 - f1: 0.4056 - val_loss: 0.1726 - val_accuracy: 0.5983 - val_f1: 0.3811 - 6s/epoch - 19ms/step\n",
      "Epoch 11/80\n",
      "327/327 - 6s - loss: 0.1822 - accuracy: 0.5808 - f1: 0.4161 - val_loss: 0.1715 - val_accuracy: 0.5914 - val_f1: 0.4040 - 6s/epoch - 19ms/step\n",
      "Epoch 12/80\n",
      "327/327 - 6s - loss: 0.1789 - accuracy: 0.5904 - f1: 0.4277 - val_loss: 0.1754 - val_accuracy: 0.5828 - val_f1: 0.3800 - 6s/epoch - 19ms/step\n",
      "Epoch 13/80\n",
      "327/327 - 6s - loss: 0.1785 - accuracy: 0.5935 - f1: 0.4297 - val_loss: 0.1699 - val_accuracy: 0.6069 - val_f1: 0.4578 - 6s/epoch - 19ms/step\n",
      "Epoch 14/80\n",
      "327/327 - 6s - loss: 0.1771 - accuracy: 0.5954 - f1: 0.4348 - val_loss: 0.1702 - val_accuracy: 0.5948 - val_f1: 0.4334 - 6s/epoch - 19ms/step\n",
      "Epoch 15/80\n",
      "327/327 - 6s - loss: 0.1768 - accuracy: 0.6004 - f1: 0.4372 - val_loss: 0.1732 - val_accuracy: 0.5931 - val_f1: 0.3747 - 6s/epoch - 19ms/step\n",
      "Epoch 16/80\n",
      "327/327 - 6s - loss: 0.1751 - accuracy: 0.5941 - f1: 0.4301 - val_loss: 0.1692 - val_accuracy: 0.6017 - val_f1: 0.4269 - 6s/epoch - 19ms/step\n",
      "Epoch 17/80\n",
      "327/327 - 6s - loss: 0.1749 - accuracy: 0.6008 - f1: 0.4382 - val_loss: 0.1691 - val_accuracy: 0.5931 - val_f1: 0.3699 - 6s/epoch - 19ms/step\n",
      "Epoch 18/80\n",
      "327/327 - 6s - loss: 0.1747 - accuracy: 0.5990 - f1: 0.4330 - val_loss: 0.1678 - val_accuracy: 0.5966 - val_f1: 0.4174 - 6s/epoch - 19ms/step\n",
      "Epoch 19/80\n",
      "327/327 - 6s - loss: 0.1711 - accuracy: 0.6044 - f1: 0.4540 - val_loss: 0.1690 - val_accuracy: 0.5948 - val_f1: 0.4206 - 6s/epoch - 19ms/step\n",
      "Epoch 20/80\n",
      "327/327 - 6s - loss: 0.1716 - accuracy: 0.6019 - f1: 0.4417 - val_loss: 0.1664 - val_accuracy: 0.6190 - val_f1: 0.4588 - 6s/epoch - 19ms/step\n",
      "Epoch 21/80\n",
      "327/327 - 6s - loss: 0.1714 - accuracy: 0.6119 - f1: 0.4460 - val_loss: 0.1722 - val_accuracy: 0.6017 - val_f1: 0.4492 - 6s/epoch - 19ms/step\n",
      "Epoch 22/80\n",
      "327/327 - 6s - loss: 0.1688 - accuracy: 0.6153 - f1: 0.4563 - val_loss: 0.1658 - val_accuracy: 0.6086 - val_f1: 0.4371 - 6s/epoch - 19ms/step\n",
      "Epoch 23/80\n",
      "327/327 - 6s - loss: 0.1690 - accuracy: 0.6159 - f1: 0.4569 - val_loss: 0.1690 - val_accuracy: 0.6121 - val_f1: 0.4608 - 6s/epoch - 19ms/step\n",
      "Epoch 24/80\n",
      "327/327 - 6s - loss: 0.1675 - accuracy: 0.6128 - f1: 0.4523 - val_loss: 0.1661 - val_accuracy: 0.6103 - val_f1: 0.4321 - 6s/epoch - 19ms/step\n",
      "Epoch 25/80\n",
      "327/327 - 6s - loss: 0.1675 - accuracy: 0.6232 - f1: 0.4569 - val_loss: 0.1701 - val_accuracy: 0.5586 - val_f1: 0.4507 - 6s/epoch - 19ms/step\n",
      "Epoch 26/80\n",
      "327/327 - 6s - loss: 0.1674 - accuracy: 0.6222 - f1: 0.4688 - val_loss: 0.1655 - val_accuracy: 0.6259 - val_f1: 0.4436 - 6s/epoch - 19ms/step\n",
      "Epoch 27/80\n",
      "327/327 - 6s - loss: 0.1669 - accuracy: 0.6188 - f1: 0.4608 - val_loss: 0.1656 - val_accuracy: 0.6034 - val_f1: 0.4116 - 6s/epoch - 19ms/step\n",
      "Epoch 28/80\n",
      "327/327 - 6s - loss: 0.1663 - accuracy: 0.6176 - f1: 0.4504 - val_loss: 0.1691 - val_accuracy: 0.6224 - val_f1: 0.4569 - 6s/epoch - 19ms/step\n",
      "Epoch 29/80\n",
      "327/327 - 6s - loss: 0.1659 - accuracy: 0.6264 - f1: 0.4697 - val_loss: 0.1658 - val_accuracy: 0.6069 - val_f1: 0.4452 - 6s/epoch - 19ms/step\n",
      "Epoch 30/80\n",
      "327/327 - 6s - loss: 0.1653 - accuracy: 0.6247 - f1: 0.4674 - val_loss: 0.1687 - val_accuracy: 0.5948 - val_f1: 0.4596 - 6s/epoch - 20ms/step\n",
      "Epoch 31/80\n",
      "327/327 - 6s - loss: 0.1652 - accuracy: 0.6222 - f1: 0.4635 - val_loss: 0.1648 - val_accuracy: 0.6103 - val_f1: 0.4286 - 6s/epoch - 19ms/step\n",
      "Epoch 32/80\n",
      "327/327 - 6s - loss: 0.1638 - accuracy: 0.6241 - f1: 0.4652 - val_loss: 0.1649 - val_accuracy: 0.6172 - val_f1: 0.4428 - 6s/epoch - 20ms/step\n",
      "Epoch 33/80\n",
      "327/327 - 7s - loss: 0.1641 - accuracy: 0.6276 - f1: 0.4593 - val_loss: 0.1652 - val_accuracy: 0.6069 - val_f1: 0.4189 - 7s/epoch - 20ms/step\n",
      "Epoch 1/80\n",
      "327/327 - 3s - loss: 0.1740 - accuracy: 0.6278 - f1: 0.4780 - val_loss: 0.1598 - val_accuracy: 0.6414 - val_f1: 0.5300 - 3s/epoch - 11ms/step\n",
      "Epoch 2/80\n",
      "327/327 - 3s - loss: 0.1512 - accuracy: 0.6690 - f1: 0.5821 - val_loss: 0.1581 - val_accuracy: 0.6397 - val_f1: 0.5473 - 3s/epoch - 8ms/step\n",
      "Epoch 3/80\n",
      "327/327 - 3s - loss: 0.1439 - accuracy: 0.6906 - f1: 0.6049 - val_loss: 0.1560 - val_accuracy: 0.6655 - val_f1: 0.5434 - 3s/epoch - 9ms/step\n",
      "Epoch 4/80\n",
      "327/327 - 3s - loss: 0.1366 - accuracy: 0.7094 - f1: 0.6459 - val_loss: 0.1595 - val_accuracy: 0.6586 - val_f1: 0.5678 - 3s/epoch - 9ms/step\n",
      "Epoch 5/80\n",
      "327/327 - 3s - loss: 0.1311 - accuracy: 0.7182 - f1: 0.6598 - val_loss: 0.1582 - val_accuracy: 0.6310 - val_f1: 0.5831 - 3s/epoch - 8ms/step\n",
      "Epoch 6/80\n",
      "327/327 - 3s - loss: 0.1271 - accuracy: 0.7297 - f1: 0.6846 - val_loss: 0.1589 - val_accuracy: 0.6586 - val_f1: 0.5924 - 3s/epoch - 8ms/step\n",
      "Epoch 7/80\n",
      "327/327 - 3s - loss: 0.1239 - accuracy: 0.7385 - f1: 0.6950 - val_loss: 0.1677 - val_accuracy: 0.6121 - val_f1: 0.5736 - 3s/epoch - 8ms/step\n",
      "Epoch 8/80\n",
      "327/327 - 3s - loss: 0.1196 - accuracy: 0.7431 - f1: 0.7156 - val_loss: 0.1650 - val_accuracy: 0.6724 - val_f1: 0.5952 - 3s/epoch - 8ms/step\n",
      "Epoch 9/80\n",
      "327/327 - 3s - loss: 0.1156 - accuracy: 0.7621 - f1: 0.7388 - val_loss: 0.1650 - val_accuracy: 0.6586 - val_f1: 0.5945 - 3s/epoch - 8ms/step\n",
      "Epoch 10/80\n",
      "327/327 - 3s - loss: 0.1119 - accuracy: 0.7663 - f1: 0.7383 - val_loss: 0.1661 - val_accuracy: 0.6017 - val_f1: 0.5471 - 3s/epoch - 8ms/step\n",
      "Epoch 11/80\n",
      "327/327 - 2s - loss: 0.1092 - accuracy: 0.7690 - f1: 0.7473 - val_loss: 0.1599 - val_accuracy: 0.6517 - val_f1: 0.6169 - 2s/epoch - 7ms/step\n",
      "Epoch 12/80\n",
      "327/327 - 2s - loss: 0.1054 - accuracy: 0.7791 - f1: 0.7669 - val_loss: 0.1638 - val_accuracy: 0.6690 - val_f1: 0.6362 - 2s/epoch - 8ms/step\n",
      "Epoch 13/80\n",
      "327/327 - 2s - loss: 0.1021 - accuracy: 0.7902 - f1: 0.7755 - val_loss: 0.1695 - val_accuracy: 0.6259 - val_f1: 0.6297 - 2s/epoch - 7ms/step\n",
      "Epoch 14/80\n",
      "327/327 - 2s - loss: 0.0985 - accuracy: 0.8002 - f1: 0.7838 - val_loss: 0.1686 - val_accuracy: 0.6431 - val_f1: 0.6197 - 2s/epoch - 7ms/step\n",
      "Epoch 15/80\n",
      "327/327 - 2s - loss: 0.0945 - accuracy: 0.8096 - f1: 0.8016 - val_loss: 0.1651 - val_accuracy: 0.6741 - val_f1: 0.6475 - 2s/epoch - 7ms/step\n",
      "Epoch 16/80\n",
      "327/327 - 2s - loss: 0.0919 - accuracy: 0.8234 - f1: 0.8174 - val_loss: 0.1698 - val_accuracy: 0.6466 - val_f1: 0.6384 - 2s/epoch - 7ms/step\n",
      "Epoch 17/80\n",
      "327/327 - 2s - loss: 0.0885 - accuracy: 0.8249 - f1: 0.8178 - val_loss: 0.1735 - val_accuracy: 0.6517 - val_f1: 0.5841 - 2s/epoch - 7ms/step\n",
      "Epoch 18/80\n",
      "327/327 - 2s - loss: 0.0849 - accuracy: 0.8398 - f1: 0.8369 - val_loss: 0.1748 - val_accuracy: 0.6534 - val_f1: 0.6129 - 2s/epoch - 8ms/step\n",
      "Epoch 19/80\n",
      "327/327 - 2s - loss: 0.0818 - accuracy: 0.8387 - f1: 0.8426 - val_loss: 0.1797 - val_accuracy: 0.6655 - val_f1: 0.6245 - 2s/epoch - 7ms/step\n",
      "Epoch 20/80\n",
      "327/327 - 2s - loss: 0.0784 - accuracy: 0.8525 - f1: 0.8550 - val_loss: 0.1863 - val_accuracy: 0.6397 - val_f1: 0.6094 - 2s/epoch - 8ms/step\n",
      "Epoch 21/80\n",
      "327/327 - 2s - loss: 0.0769 - accuracy: 0.8546 - f1: 0.8617 - val_loss: 0.1905 - val_accuracy: 0.6672 - val_f1: 0.6274 - 2s/epoch - 8ms/step\n",
      "Epoch 22/80\n",
      "327/327 - 2s - loss: 0.0729 - accuracy: 0.8693 - f1: 0.8725 - val_loss: 0.2150 - val_accuracy: 0.6759 - val_f1: 0.6149 - 2s/epoch - 8ms/step\n",
      "Epoch 23/80\n",
      "327/327 - 2s - loss: 0.0690 - accuracy: 0.8839 - f1: 0.8867 - val_loss: 0.2041 - val_accuracy: 0.6655 - val_f1: 0.6117 - 2s/epoch - 7ms/step\n",
      "Epoch 24/80\n",
      "327/327 - 2s - loss: 0.0677 - accuracy: 0.8761 - f1: 0.8837 - val_loss: 0.1952 - val_accuracy: 0.6534 - val_f1: 0.6134 - 2s/epoch - 7ms/step\n",
      "Epoch 25/80\n",
      "327/327 - 2s - loss: 0.0660 - accuracy: 0.8841 - f1: 0.8951 - val_loss: 0.1932 - val_accuracy: 0.6414 - val_f1: 0.6201 - 2s/epoch - 7ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.67      0.85      0.75       310\n",
      "           D       0.60      0.37      0.46       167\n",
      "           G       0.77      0.38      0.51        26\n",
      "           C       0.79      0.90      0.84        29\n",
      "           A       0.88      0.29      0.44        24\n",
      "           M       0.79      0.96      0.87        24\n",
      "\n",
      "    accuracy                           0.68       580\n",
      "   macro avg       0.75      0.63      0.64       580\n",
      "weighted avg       0.67      0.68      0.65       580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Modelo 2 - Dataset Desbalanceado ###\n",
    "\n",
    "import os, sys, cv2, numpy as np, pandas as pd, torch, argparse\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_recall_curve, classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Config\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 80\n",
    "LABELS = ['N','D','G','C','A','M']\n",
    "LABEL_MAP = {c:i for i,c in enumerate(LABELS)}\n",
    "ENSEMBLE_W = 0.7\n",
    "\n",
    "# Añadir RETFound\n",
    "sys.path.append(r\"C:/Users/34629/Downloads/RETFound_MAE\")\n",
    "from models_vit import RETFound_mae\n",
    "from util.pos_embed import interpolate_pos_embed\n",
    "torch.serialization.add_safe_globals([argparse.Namespace])\n",
    "\n",
    "# Paths\n",
    "rf_train_path = \"C:/Users/34629/Downloads/X_rf_train_DES.npy\"\n",
    "rf_val_path   = \"C:/Users/34629/Downloads/X_rf_val_DES.npy\"\n",
    "eff_train_path = \"C:/Users/34629/Downloads/X_eff_train_DES.npy\"\n",
    "eff_val_path   = \"C:/Users/34629/Downloads/X_eff_val_DES.npy\"\n",
    "y_train_path = \"C:/Users/34629/Downloads/y_train_DES.npy\"\n",
    "y_val_path   = \"C:/Users/34629/Downloads/y_val_DES.npy\"\n",
    "\n",
    "train_df = pd.read_csv(\"C:/Users/34629/TFG/train_DES.csv\")\n",
    "val_df = pd.read_csv(\"C:/Users/34629/TFG/val_DES.csv\")\n",
    "\n",
    "train_df['label'] = train_df['class_label'].map(LABEL_MAP)\n",
    "val_df['label'] = val_df['class_label'].map(LABEL_MAP)\n",
    "\n",
    "train_paths = train_df['Image_Path'].tolist()\n",
    "val_paths = val_df['Image_Path'].tolist()\n",
    "y_tr = train_df['label'].values\n",
    "y_vl = val_df['label'].values\n",
    "\n",
    "# Función extracción EfficientNet\n",
    "from tensorflow.keras.applications import EfficientNetB3, efficientnet\n",
    "eff_model = EfficientNetB3(include_top=False, pooling='avg', weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "def extract_eff_features(paths):\n",
    "    feats = []\n",
    "    for p in tqdm(paths, desc=\"EffNet feats\"):\n",
    "        img = cv2.resize(cv2.imread(p), (IMG_SIZE, IMG_SIZE))\n",
    "        x = efficientnet.preprocess_input(img.astype('float32'))\n",
    "        feats.append(eff_model(np.expand_dims(x, 0), training=False).numpy().squeeze())\n",
    "    return np.stack(feats)\n",
    "\n",
    "# Cargar o extraer características\n",
    "if all(os.path.exists(p) for p in [rf_train_path, rf_val_path, y_train_path, y_val_path]):\n",
    "    X1_tr = np.load(rf_train_path)\n",
    "    X1_vl = np.load(rf_val_path)\n",
    "    y_tr  = np.load(y_train_path)\n",
    "    y_vl  = np.load(y_val_path)\n",
    "    print(\"✅ RETFound cargado de disco.\")\n",
    "else:\n",
    "    def extract_retfound_features(paths):\n",
    "        model = RETFound_mae(global_pool=True, img_size=IMG_SIZE)\n",
    "        ckpt = torch.load(\"C:/Users/34629/Downloads/RETFound_MAE/RETFound_cfp_weights.pth\", map_location='cpu')\n",
    "        sd = ckpt['model']; sd.pop('head.weight', None); sd.pop('head.bias', None)\n",
    "        interpolate_pos_embed(model, sd)\n",
    "        model.load_state_dict(sd, strict=False); model.eval()\n",
    "        feats = []\n",
    "        for p in tqdm(paths, desc=\"RETFound feats\"):\n",
    "            img = cv2.resize(cv2.imread(p), (IMG_SIZE, IMG_SIZE)) / 255.0\n",
    "            x = torch.from_numpy(img.astype('float32')).permute(2,0,1).unsqueeze(0)\n",
    "            with torch.no_grad():\n",
    "                f = model.forward_features(x).cpu().numpy().squeeze()\n",
    "            feats.append(f)\n",
    "        return np.stack(feats)\n",
    "\n",
    "    X1_tr = extract_retfound_features(train_paths)\n",
    "    X1_vl = extract_retfound_features(val_paths)\n",
    "    np.save(rf_train_path, X1_tr)\n",
    "    np.save(rf_val_path, X1_vl)\n",
    "    np.save(y_train_path, y_tr)\n",
    "    np.save(y_val_path, y_vl)\n",
    "\n",
    "if all(os.path.exists(p) for p in [eff_train_path, eff_val_path]):\n",
    "    X2_tr = np.load(eff_train_path)\n",
    "    X2_vl = np.load(eff_val_path)\n",
    "    print(\"✅ EfficientNet cargado de disco.\")\n",
    "else:\n",
    "    X2_tr = extract_eff_features(train_paths)\n",
    "    X2_vl = extract_eff_features(val_paths)\n",
    "    np.save(eff_train_path, X2_tr)\n",
    "    np.save(eff_val_path, X2_vl)\n",
    "\n",
    "# One-hot\n",
    "y_tr_cat = to_categorical(y_tr, num_classes=len(LABELS))\n",
    "y_vl_cat = to_categorical(y_vl, num_classes=len(LABELS))\n",
    "\n",
    "# Modelos\n",
    "inp1 = Input((X1_tr.shape[1],))\n",
    "x = Dense(1024)(inp1); x = LayerNormalization()(x); x = LeakyReLU(0.1)(x)\n",
    "x = Dropout(0.5)(x); x = Dense(512)(x); x = LayerNormalization()(x); x = LeakyReLU(0.1)(x)\n",
    "x = Dropout(0.4)(x); x = Dense(256)(x); x = LayerNormalization()(x); x = LeakyReLU(0.1)(x)\n",
    "x = Dropout(0.3)(x); out1 = Dense(len(LABELS), activation='softmax')(x)\n",
    "m1 = Model(inp1, out1)\n",
    "\n",
    "inp2 = Input((X2_tr.shape[1],))\n",
    "y_ = Dense(512, activation='relu')(inp2)\n",
    "out2 = Dense(len(LABELS), activation='softmax')(y_)\n",
    "m2 = Model(inp2, out2)\n",
    "\n",
    "loss_fn = tfa.losses.SigmoidFocalCrossEntropy(from_logits=False)\n",
    "for model in [m1, m2]:\n",
    "    model.compile(optimizer=Adam(1e-4),\n",
    "                  loss=loss_fn,\n",
    "                  metrics=['accuracy', tfa.metrics.F1Score(num_classes=len(LABELS), average='macro', name='f1')])\n",
    "\n",
    "cb_rf = [EarlyStopping('val_f1', mode='max', patience=10, restore_best_weights=True),\n",
    "         ModelCheckpoint(\"Clas_DES_rf_modelo2.h5\", monitor='val_f1', save_best_only=True)]\n",
    "cb_eff = [EarlyStopping('val_f1', mode='max', patience=10, restore_best_weights=True),\n",
    "          ModelCheckpoint(\"Clas_DES_eff_modelo2.h5\", monitor='val_f1', save_best_only=True)]\n",
    "\n",
    "# Entrenamiento\n",
    "m1.fit(X1_tr, y_tr_cat, validation_data=(X1_vl, y_vl_cat), epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=cb_rf, verbose=2)\n",
    "m2.fit(X2_tr, y_tr_cat, validation_data=(X2_vl, y_vl_cat), epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=cb_eff, verbose=2)\n",
    "\n",
    "# Ensemble + umbrales\n",
    "p1 = m1.predict(X1_vl)\n",
    "p2 = m2.predict(X2_vl)\n",
    "probs = ENSEMBLE_W * p1 + (1 - ENSEMBLE_W) * p2\n",
    "THRESH = np.ones(len(LABELS)) * 0.5\n",
    "for i in range(len(LABELS)):\n",
    "    prec, rec, thr = precision_recall_curve((y_vl == i).astype(int), probs[:, i])\n",
    "    F = 2 * prec * rec / (prec + rec + 1e-8)\n",
    "    THRESH[i] = thr[np.nanargmax(F)]\n",
    "\n",
    "y_pred = []\n",
    "for row in probs:\n",
    "    sel = np.where(row >= THRESH)[0]\n",
    "    if len(sel) == 1: y_pred.append(sel[0])\n",
    "    elif len(sel) > 1: y_pred.append(sel[np.argmax(row[sel])])\n",
    "    else: y_pred.append(int(np.argmax(row)))\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Reporte\n",
    "print(classification_report(y_vl, y_pred, target_names=LABELS))\n",
    "cm = confusion_matrix(y_vl, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=LABELS, yticklabels=LABELS)\n",
    "plt.title(\"Matriz Confusión Modelo 2 DES\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"matriz_confusion_modelo2_DES.png\")\n",
    "plt.close()\n",
    "\n",
    "# ROC\n",
    "y_true_bin = label_binarize(y_vl, classes=np.arange(len(LABELS)))\n",
    "plt.figure(figsize=(10,7))\n",
    "for i in range(len(LABELS)):\n",
    "    fpr, tpr, _ = roc_curve(y_true_bin[:, i], probs[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f\"{LABELS[i]} (AUC={roc_auc:.2f})\")\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.title(\"Curva ROC Modelo 2 DES\"); plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"curva_ROC_modelo2_DES.png\")\n",
    "plt.close()\n",
    "\n",
    "# Grad-CAM\n",
    "def generar_gradcam(img_path, nombre_archivo):\n",
    "    model = RETFound_mae(global_pool=False, img_size=IMG_SIZE)\n",
    "    ckpt = torch.load(\"C:/Users/34629/Downloads/RETFound_MAE/RETFound_cfp_weights.pth\", map_location='cpu')\n",
    "    sd = ckpt['model']; sd.pop('head.weight', None); sd.pop('head.bias', None)\n",
    "    interpolate_pos_embed(model, sd)\n",
    "    model.load_state_dict(sd, strict=False); model.eval()\n",
    "    activations = {}\n",
    "    model.blocks[11].register_forward_hook(lambda m, i, o: activations.update({'value': o}))\n",
    "    img = Image.open(img_path).convert('RGB').resize((IMG_SIZE, IMG_SIZE))\n",
    "    x = transforms.ToTensor()(img).unsqueeze(0)\n",
    "    with torch.no_grad(): model(x)\n",
    "    cam = activations['value'].squeeze(0).numpy()[1:].mean(axis=1).reshape(14, 14)\n",
    "    cam = cv2.resize((cam - cam.min()) / (cam.max() - cam.min()), (IMG_SIZE, IMG_SIZE))\n",
    "    cam = np.uint8(255 * cam)\n",
    "    cam_color = cv2.applyColorMap(cam, cv2.COLORMAP_JET)\n",
    "    superpuesta = 0.4 * np.array(img) + 0.6 * cam_color\n",
    "    cv2.imwrite(nombre_archivo, cv2.cvtColor(np.uint8(superpuesta), cv2.COLOR_RGB2BGR))\n",
    "\n",
    "df_res = pd.DataFrame({'img': val_paths, 'true': y_vl, 'pred': y_pred})\n",
    "df_res['correct'] = df_res['true'] == df_res['pred']\n",
    "bien = df_res[df_res['correct']].iloc[0]\n",
    "mal  = df_res[~df_res['correct']].iloc[0]\n",
    "generar_gradcam(bien['img'], f\"gradcam_DES_modelo2_correcto_{LABELS[bien['pred']]}.png\")\n",
    "generar_gradcam(mal['img'],  f\"gradcam_DES_modelo2_error_{LABELS[mal['true']]}_pred{LABELS[mal['pred']]}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2244e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "WARNING:tensorflow:From c:\\Users\\34629\\TFG\\env\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "327/327 - 10s - loss: 2.2788 - accuracy: 0.4128 - f1_score: 0.2564 - val_loss: 2.0826 - val_accuracy: 0.5500 - val_f1_score: 0.4365 - 10s/epoch - 30ms/step\n",
      "Epoch 2/80\n",
      "327/327 - 7s - loss: 2.1048 - accuracy: 0.5067 - f1_score: 0.3193 - val_loss: 1.9519 - val_accuracy: 0.5500 - val_f1_score: 0.4777 - 7s/epoch - 23ms/step\n",
      "Epoch 3/80\n",
      "327/327 - 8s - loss: 1.9687 - accuracy: 0.5148 - f1_score: 0.3321 - val_loss: 1.8218 - val_accuracy: 0.5759 - val_f1_score: 0.5010 - 8s/epoch - 24ms/step\n",
      "Epoch 4/80\n",
      "327/327 - 8s - loss: 1.8385 - accuracy: 0.5276 - f1_score: 0.3493 - val_loss: 1.6918 - val_accuracy: 0.5621 - val_f1_score: 0.4931 - 8s/epoch - 25ms/step\n",
      "Epoch 5/80\n",
      "327/327 - 8s - loss: 1.7028 - accuracy: 0.5370 - f1_score: 0.3563 - val_loss: 1.5631 - val_accuracy: 0.6069 - val_f1_score: 0.5142 - 8s/epoch - 24ms/step\n",
      "Epoch 6/80\n",
      "327/327 - 7s - loss: 1.5815 - accuracy: 0.5324 - f1_score: 0.3559 - val_loss: 1.4447 - val_accuracy: 0.5948 - val_f1_score: 0.4823 - 7s/epoch - 22ms/step\n",
      "Epoch 7/80\n",
      "327/327 - 8s - loss: 1.4628 - accuracy: 0.5481 - f1_score: 0.3719 - val_loss: 1.3332 - val_accuracy: 0.5810 - val_f1_score: 0.4789 - 8s/epoch - 25ms/step\n",
      "Epoch 8/80\n",
      "327/327 - 9s - loss: 1.3492 - accuracy: 0.5525 - f1_score: 0.3678 - val_loss: 1.2241 - val_accuracy: 0.5897 - val_f1_score: 0.4605 - 9s/epoch - 29ms/step\n",
      "Epoch 9/80\n",
      "327/327 - 8s - loss: 1.2387 - accuracy: 0.5636 - f1_score: 0.3770 - val_loss: 1.1244 - val_accuracy: 0.6034 - val_f1_score: 0.4396 - 8s/epoch - 24ms/step\n",
      "Epoch 10/80\n",
      "327/327 - 8s - loss: 1.1423 - accuracy: 0.5594 - f1_score: 0.3757 - val_loss: 1.0293 - val_accuracy: 0.6069 - val_f1_score: 0.5083 - 8s/epoch - 23ms/step\n",
      "Epoch 11/80\n",
      "327/327 - 7s - loss: 1.0483 - accuracy: 0.5542 - f1_score: 0.3724 - val_loss: 0.9389 - val_accuracy: 0.6138 - val_f1_score: 0.4934 - 7s/epoch - 23ms/step\n",
      "Epoch 12/80\n",
      "327/327 - 7s - loss: 0.9600 - accuracy: 0.5755 - f1_score: 0.3832 - val_loss: 0.8614 - val_accuracy: 0.5828 - val_f1_score: 0.5037 - 7s/epoch - 23ms/step\n",
      "Epoch 13/80\n",
      "327/327 - 7s - loss: 0.8836 - accuracy: 0.5707 - f1_score: 0.3839 - val_loss: 0.7905 - val_accuracy: 0.5862 - val_f1_score: 0.4873 - 7s/epoch - 23ms/step\n",
      "Epoch 14/80\n",
      "327/327 - 7s - loss: 0.8126 - accuracy: 0.5791 - f1_score: 0.3883 - val_loss: 0.7177 - val_accuracy: 0.5948 - val_f1_score: 0.5024 - 7s/epoch - 23ms/step\n",
      "Epoch 15/80\n",
      "327/327 - 8s - loss: 0.7474 - accuracy: 0.5772 - f1_score: 0.3873 - val_loss: 0.6569 - val_accuracy: 0.6103 - val_f1_score: 0.5130 - 8s/epoch - 24ms/step\n",
      "Epoch 16/80\n",
      "327/327 - 8s - loss: 0.6894 - accuracy: 0.5904 - f1_score: 0.3976 - val_loss: 0.6041 - val_accuracy: 0.6034 - val_f1_score: 0.5513 - 8s/epoch - 24ms/step\n",
      "Epoch 17/80\n",
      "327/327 - 8s - loss: 0.6368 - accuracy: 0.5858 - f1_score: 0.3960 - val_loss: 0.5562 - val_accuracy: 0.6345 - val_f1_score: 0.5173 - 8s/epoch - 25ms/step\n",
      "Epoch 18/80\n",
      "327/327 - 8s - loss: 0.5902 - accuracy: 0.5795 - f1_score: 0.3888 - val_loss: 0.5053 - val_accuracy: 0.6345 - val_f1_score: 0.4848 - 8s/epoch - 25ms/step\n",
      "Epoch 19/80\n",
      "327/327 - 8s - loss: 0.5445 - accuracy: 0.5971 - f1_score: 0.4110 - val_loss: 0.4841 - val_accuracy: 0.6103 - val_f1_score: 0.4956 - 8s/epoch - 25ms/step\n",
      "Epoch 20/80\n",
      "327/327 - 7s - loss: 0.5085 - accuracy: 0.5851 - f1_score: 0.3999 - val_loss: 0.4332 - val_accuracy: 0.6138 - val_f1_score: 0.4938 - 7s/epoch - 22ms/step\n",
      "Epoch 21/80\n",
      "327/327 - 7s - loss: 0.4736 - accuracy: 0.5929 - f1_score: 0.4016 - val_loss: 0.4086 - val_accuracy: 0.6121 - val_f1_score: 0.5194 - 7s/epoch - 22ms/step\n",
      "Epoch 22/80\n",
      "327/327 - 7s - loss: 0.4436 - accuracy: 0.5906 - f1_score: 0.4063 - val_loss: 0.3770 - val_accuracy: 0.5931 - val_f1_score: 0.4866 - 7s/epoch - 22ms/step\n",
      "Epoch 23/80\n",
      "327/327 - 7s - loss: 0.4161 - accuracy: 0.6098 - f1_score: 0.4161 - val_loss: 0.3502 - val_accuracy: 0.6310 - val_f1_score: 0.5671 - 7s/epoch - 20ms/step\n",
      "Epoch 24/80\n",
      "327/327 - 7s - loss: 0.3916 - accuracy: 0.6134 - f1_score: 0.4263 - val_loss: 0.3271 - val_accuracy: 0.6259 - val_f1_score: 0.5243 - 7s/epoch - 23ms/step\n",
      "Epoch 25/80\n",
      "327/327 - 8s - loss: 0.3694 - accuracy: 0.6094 - f1_score: 0.4147 - val_loss: 0.3037 - val_accuracy: 0.6310 - val_f1_score: 0.5300 - 8s/epoch - 23ms/step\n",
      "Epoch 26/80\n",
      "327/327 - 7s - loss: 0.3507 - accuracy: 0.6100 - f1_score: 0.4076 - val_loss: 0.2913 - val_accuracy: 0.6138 - val_f1_score: 0.5039 - 7s/epoch - 21ms/step\n",
      "Epoch 27/80\n",
      "327/327 - 7s - loss: 0.3342 - accuracy: 0.6102 - f1_score: 0.4095 - val_loss: 0.2722 - val_accuracy: 0.6034 - val_f1_score: 0.5071 - 7s/epoch - 21ms/step\n",
      "Epoch 28/80\n",
      "327/327 - 7s - loss: 0.3172 - accuracy: 0.6113 - f1_score: 0.4229 - val_loss: 0.2588 - val_accuracy: 0.6172 - val_f1_score: 0.5097 - 7s/epoch - 20ms/step\n",
      "Epoch 29/80\n",
      "327/327 - 7s - loss: 0.3041 - accuracy: 0.6192 - f1_score: 0.4215 - val_loss: 0.2545 - val_accuracy: 0.6000 - val_f1_score: 0.4955 - 7s/epoch - 22ms/step\n",
      "Epoch 30/80\n",
      "327/327 - 7s - loss: 0.2922 - accuracy: 0.6186 - f1_score: 0.4217 - val_loss: 0.2352 - val_accuracy: 0.6241 - val_f1_score: 0.4724 - 7s/epoch - 22ms/step\n",
      "Epoch 31/80\n",
      "327/327 - 7s - loss: 0.2813 - accuracy: 0.6257 - f1_score: 0.4125 - val_loss: 0.2302 - val_accuracy: 0.6224 - val_f1_score: 0.5134 - 7s/epoch - 22ms/step\n",
      "Epoch 32/80\n",
      "327/327 - 7s - loss: 0.2692 - accuracy: 0.6316 - f1_score: 0.4315 - val_loss: 0.2143 - val_accuracy: 0.6259 - val_f1_score: 0.5278 - 7s/epoch - 22ms/step\n",
      "Epoch 33/80\n",
      "327/327 - 7s - loss: 0.2623 - accuracy: 0.6180 - f1_score: 0.4177 - val_loss: 0.2100 - val_accuracy: 0.6224 - val_f1_score: 0.4639 - 7s/epoch - 22ms/step\n",
      "Epoch 34/80\n",
      "327/327 - 7s - loss: 0.2530 - accuracy: 0.6249 - f1_score: 0.4213 - val_loss: 0.2018 - val_accuracy: 0.6345 - val_f1_score: 0.4974 - 7s/epoch - 22ms/step\n",
      "Epoch 35/80\n",
      "327/327 - 8s - loss: 0.2476 - accuracy: 0.6205 - f1_score: 0.4160 - val_loss: 0.1987 - val_accuracy: 0.6362 - val_f1_score: 0.5292 - 8s/epoch - 25ms/step\n",
      "Epoch 36/80\n",
      "327/327 - 8s - loss: 0.2387 - accuracy: 0.6285 - f1_score: 0.4280 - val_loss: 0.1893 - val_accuracy: 0.6345 - val_f1_score: 0.5269 - 8s/epoch - 24ms/step\n",
      "Epoch 37/80\n",
      "327/327 - 7s - loss: 0.2342 - accuracy: 0.6245 - f1_score: 0.4240 - val_loss: 0.1831 - val_accuracy: 0.6466 - val_f1_score: 0.5191 - 7s/epoch - 21ms/step\n",
      "Epoch 38/80\n",
      "327/327 - 7s - loss: 0.2298 - accuracy: 0.6282 - f1_score: 0.4237 - val_loss: 0.1835 - val_accuracy: 0.6276 - val_f1_score: 0.4715 - 7s/epoch - 22ms/step\n",
      "Epoch 39/80\n",
      "327/327 - 8s - loss: 0.2252 - accuracy: 0.6274 - f1_score: 0.4147 - val_loss: 0.1785 - val_accuracy: 0.6017 - val_f1_score: 0.5246 - 8s/epoch - 24ms/step\n",
      "Epoch 40/80\n",
      "327/327 - 8s - loss: 0.2202 - accuracy: 0.6284 - f1_score: 0.4232 - val_loss: 0.1702 - val_accuracy: 0.6397 - val_f1_score: 0.5128 - 8s/epoch - 23ms/step\n",
      "Epoch 41/80\n",
      "327/327 - 8s - loss: 0.2168 - accuracy: 0.6282 - f1_score: 0.4199 - val_loss: 0.1766 - val_accuracy: 0.6345 - val_f1_score: 0.5403 - 8s/epoch - 23ms/step\n",
      "Epoch 42/80\n",
      "327/327 - 8s - loss: 0.2109 - accuracy: 0.6351 - f1_score: 0.4343 - val_loss: 0.1675 - val_accuracy: 0.6276 - val_f1_score: 0.5238 - 8s/epoch - 23ms/step\n",
      "Epoch 43/80\n",
      "327/327 - 8s - loss: 0.2083 - accuracy: 0.6397 - f1_score: 0.4309 - val_loss: 0.1607 - val_accuracy: 0.6276 - val_f1_score: 0.5334 - 8s/epoch - 23ms/step\n",
      "Epoch 44/80\n",
      "327/327 - 7s - loss: 0.2070 - accuracy: 0.6295 - f1_score: 0.4268 - val_loss: 0.1654 - val_accuracy: 0.6155 - val_f1_score: 0.5128 - 7s/epoch - 23ms/step\n",
      "Epoch 45/80\n",
      "327/327 - 7s - loss: 0.2033 - accuracy: 0.6389 - f1_score: 0.4307 - val_loss: 0.1542 - val_accuracy: 0.6397 - val_f1_score: 0.5066 - 7s/epoch - 23ms/step\n",
      "Epoch 46/80\n",
      "327/327 - 8s - loss: 0.1993 - accuracy: 0.6423 - f1_score: 0.4401 - val_loss: 0.1595 - val_accuracy: 0.6086 - val_f1_score: 0.5364 - 8s/epoch - 25ms/step\n",
      "Epoch 47/80\n",
      "327/327 - 7s - loss: 0.1983 - accuracy: 0.6423 - f1_score: 0.4390 - val_loss: 0.1480 - val_accuracy: 0.6328 - val_f1_score: 0.5470 - 7s/epoch - 21ms/step\n",
      "Epoch 48/80\n",
      "327/327 - 7s - loss: 0.1963 - accuracy: 0.6354 - f1_score: 0.4353 - val_loss: 0.1491 - val_accuracy: 0.6552 - val_f1_score: 0.5754 - 7s/epoch - 22ms/step\n",
      "Epoch 49/80\n",
      "327/327 - 7s - loss: 0.1924 - accuracy: 0.6421 - f1_score: 0.4404 - val_loss: 0.1499 - val_accuracy: 0.6259 - val_f1_score: 0.5539 - 7s/epoch - 23ms/step\n",
      "Epoch 50/80\n",
      "327/327 - 7s - loss: 0.1910 - accuracy: 0.6297 - f1_score: 0.4320 - val_loss: 0.1556 - val_accuracy: 0.6190 - val_f1_score: 0.5332 - 7s/epoch - 23ms/step\n",
      "Epoch 51/80\n",
      "327/327 - 7s - loss: 0.1909 - accuracy: 0.6408 - f1_score: 0.4376 - val_loss: 0.1391 - val_accuracy: 0.6466 - val_f1_score: 0.5167 - 7s/epoch - 22ms/step\n",
      "Epoch 52/80\n",
      "327/327 - 7s - loss: 0.1888 - accuracy: 0.6285 - f1_score: 0.4342 - val_loss: 0.1418 - val_accuracy: 0.6052 - val_f1_score: 0.5552 - 7s/epoch - 22ms/step\n",
      "Epoch 53/80\n",
      "327/327 - 7s - loss: 0.1876 - accuracy: 0.6366 - f1_score: 0.4421 - val_loss: 0.1512 - val_accuracy: 0.6121 - val_f1_score: 0.5249 - 7s/epoch - 21ms/step\n",
      "Epoch 54/80\n",
      "327/327 - 8s - loss: 0.1861 - accuracy: 0.6498 - f1_score: 0.4458 - val_loss: 0.1448 - val_accuracy: 0.6086 - val_f1_score: 0.5347 - 8s/epoch - 25ms/step\n",
      "Epoch 55/80\n",
      "327/327 - 8s - loss: 0.1854 - accuracy: 0.6404 - f1_score: 0.4401 - val_loss: 0.1322 - val_accuracy: 0.6345 - val_f1_score: 0.5414 - 8s/epoch - 25ms/step\n",
      "Epoch 56/80\n",
      "327/327 - 8s - loss: 0.1843 - accuracy: 0.6358 - f1_score: 0.4350 - val_loss: 0.1393 - val_accuracy: 0.6259 - val_f1_score: 0.5183 - 8s/epoch - 23ms/step\n",
      "Epoch 57/80\n",
      "327/327 - 9s - loss: 0.1820 - accuracy: 0.6471 - f1_score: 0.4547 - val_loss: 0.1381 - val_accuracy: 0.6259 - val_f1_score: 0.4959 - 9s/epoch - 26ms/step\n",
      "Epoch 58/80\n",
      "327/327 - 8s - loss: 0.1820 - accuracy: 0.6347 - f1_score: 0.4365 - val_loss: 0.1369 - val_accuracy: 0.6224 - val_f1_score: 0.4721 - 8s/epoch - 25ms/step\n",
      "Epoch 59/80\n",
      "327/327 - 11s - loss: 0.1811 - accuracy: 0.6441 - f1_score: 0.4395 - val_loss: 0.1471 - val_accuracy: 0.6052 - val_f1_score: 0.5520 - 11s/epoch - 33ms/step\n",
      "Epoch 60/80\n",
      "327/327 - 10s - loss: 0.1813 - accuracy: 0.6429 - f1_score: 0.4289 - val_loss: 0.1335 - val_accuracy: 0.6259 - val_f1_score: 0.5339 - 10s/epoch - 32ms/step\n",
      "Epoch 61/80\n",
      "327/327 - 11s - loss: 0.1787 - accuracy: 0.6492 - f1_score: 0.4478 - val_loss: 0.1282 - val_accuracy: 0.6397 - val_f1_score: 0.5374 - 11s/epoch - 34ms/step\n",
      "Epoch 62/80\n",
      "327/327 - 12s - loss: 0.1779 - accuracy: 0.6450 - f1_score: 0.4505 - val_loss: 0.1332 - val_accuracy: 0.6379 - val_f1_score: 0.5233 - 12s/epoch - 36ms/step\n",
      "Epoch 63/80\n",
      "327/327 - 12s - loss: 0.1775 - accuracy: 0.6352 - f1_score: 0.4365 - val_loss: 0.1384 - val_accuracy: 0.6052 - val_f1_score: 0.5263 - 12s/epoch - 36ms/step\n",
      "Epoch 64/80\n",
      "327/327 - 12s - loss: 0.1775 - accuracy: 0.6456 - f1_score: 0.4444 - val_loss: 0.1385 - val_accuracy: 0.6172 - val_f1_score: 0.5985 - 12s/epoch - 37ms/step\n",
      "Epoch 65/80\n",
      "327/327 - 12s - loss: 0.1773 - accuracy: 0.6391 - f1_score: 0.4431 - val_loss: 0.1341 - val_accuracy: 0.5793 - val_f1_score: 0.5211 - 12s/epoch - 36ms/step\n",
      "Epoch 66/80\n",
      "327/327 - 11s - loss: 0.1761 - accuracy: 0.6508 - f1_score: 0.4538 - val_loss: 0.1299 - val_accuracy: 0.6241 - val_f1_score: 0.5577 - 11s/epoch - 35ms/step\n",
      "Epoch 67/80\n",
      "327/327 - 11s - loss: 0.1762 - accuracy: 0.6446 - f1_score: 0.4545 - val_loss: 0.1291 - val_accuracy: 0.6207 - val_f1_score: 0.5322 - 11s/epoch - 34ms/step\n",
      "Epoch 68/80\n",
      "327/327 - 12s - loss: 0.1769 - accuracy: 0.6324 - f1_score: 0.4293 - val_loss: 0.1364 - val_accuracy: 0.6276 - val_f1_score: 0.5218 - 12s/epoch - 38ms/step\n",
      "Epoch 69/80\n",
      "327/327 - 10s - loss: 0.1742 - accuracy: 0.6469 - f1_score: 0.4472 - val_loss: 0.1299 - val_accuracy: 0.6310 - val_f1_score: 0.5314 - 10s/epoch - 30ms/step\n",
      "Epoch 70/80\n",
      "327/327 - 10s - loss: 0.1744 - accuracy: 0.6456 - f1_score: 0.4503 - val_loss: 0.1301 - val_accuracy: 0.6517 - val_f1_score: 0.5452 - 10s/epoch - 29ms/step\n",
      "Epoch 71/80\n",
      "327/327 - 10s - loss: 0.1755 - accuracy: 0.6456 - f1_score: 0.4470 - val_loss: 0.1364 - val_accuracy: 0.6241 - val_f1_score: 0.4986 - 10s/epoch - 30ms/step\n",
      "Epoch 72/80\n",
      "327/327 - 10s - loss: 0.1737 - accuracy: 0.6519 - f1_score: 0.4471 - val_loss: 0.1531 - val_accuracy: 0.6103 - val_f1_score: 0.5619 - 10s/epoch - 29ms/step\n",
      "Epoch 73/80\n",
      "327/327 - 8s - loss: 0.1735 - accuracy: 0.6473 - f1_score: 0.4553 - val_loss: 0.1450 - val_accuracy: 0.5914 - val_f1_score: 0.5686 - 8s/epoch - 24ms/step\n",
      "Epoch 74/80\n",
      "327/327 - 7s - loss: 0.1721 - accuracy: 0.6508 - f1_score: 0.4567 - val_loss: 0.1354 - val_accuracy: 0.5638 - val_f1_score: 0.5588 - 7s/epoch - 22ms/step\n",
      "Epoch 75/80\n",
      "327/327 - 7s - loss: 0.1741 - accuracy: 0.6454 - f1_score: 0.4461 - val_loss: 0.1287 - val_accuracy: 0.6328 - val_f1_score: 0.5704 - 7s/epoch - 22ms/step\n",
      "Epoch 76/80\n",
      "327/327 - 7s - loss: 0.1728 - accuracy: 0.6481 - f1_score: 0.4555 - val_loss: 0.1397 - val_accuracy: 0.6138 - val_f1_score: 0.5407 - 7s/epoch - 22ms/step\n",
      "Epoch 77/80\n",
      "327/327 - 7s - loss: 0.1724 - accuracy: 0.6492 - f1_score: 0.4480 - val_loss: 0.1415 - val_accuracy: 0.6190 - val_f1_score: 0.5450 - 7s/epoch - 22ms/step\n",
      "Epoch 78/80\n",
      "327/327 - 7s - loss: 0.1716 - accuracy: 0.6494 - f1_score: 0.4557 - val_loss: 0.1306 - val_accuracy: 0.6241 - val_f1_score: 0.4976 - 7s/epoch - 22ms/step\n",
      "Epoch 79/80\n",
      "327/327 - 7s - loss: 0.1716 - accuracy: 0.6481 - f1_score: 0.4467 - val_loss: 0.1348 - val_accuracy: 0.6483 - val_f1_score: 0.5419 - 7s/epoch - 22ms/step\n",
      "Epoch 80/80\n",
      "327/327 - 7s - loss: 0.1720 - accuracy: 0.6494 - f1_score: 0.4468 - val_loss: 0.1286 - val_accuracy: 0.6121 - val_f1_score: 0.5259 - 7s/epoch - 22ms/step\n",
      "Epoch 1/80\n",
      "327/327 - 4s - loss: 1.0272 - accuracy: 0.4034 - f1_score: 0.1607 - val_loss: 0.9077 - val_accuracy: 0.5345 - val_f1_score: 0.1314 - 4s/epoch - 12ms/step\n",
      "Epoch 2/80\n",
      "327/327 - 3s - loss: 0.9121 - accuracy: 0.4467 - f1_score: 0.1713 - val_loss: 0.8311 - val_accuracy: 0.3655 - val_f1_score: 0.1537 - 3s/epoch - 10ms/step\n",
      "Epoch 3/80\n",
      "327/327 - 3s - loss: 0.8271 - accuracy: 0.4619 - f1_score: 0.1850 - val_loss: 0.7947 - val_accuracy: 0.3517 - val_f1_score: 0.1267 - 3s/epoch - 9ms/step\n",
      "Epoch 4/80\n",
      "327/327 - 3s - loss: 0.7578 - accuracy: 0.4730 - f1_score: 0.1891 - val_loss: 0.7135 - val_accuracy: 0.4621 - val_f1_score: 0.1428 - 3s/epoch - 9ms/step\n",
      "Epoch 5/80\n",
      "327/327 - 3s - loss: 0.6978 - accuracy: 0.4845 - f1_score: 0.2114 - val_loss: 0.6711 - val_accuracy: 0.5000 - val_f1_score: 0.1401 - 3s/epoch - 9ms/step\n",
      "Epoch 6/80\n",
      "327/327 - 3s - loss: 0.6459 - accuracy: 0.5027 - f1_score: 0.2218 - val_loss: 0.6305 - val_accuracy: 0.5052 - val_f1_score: 0.1335 - 3s/epoch - 9ms/step\n",
      "Epoch 7/80\n",
      "327/327 - 3s - loss: 0.6011 - accuracy: 0.5084 - f1_score: 0.2237 - val_loss: 0.5781 - val_accuracy: 0.4931 - val_f1_score: 0.1599 - 3s/epoch - 10ms/step\n",
      "Epoch 8/80\n",
      "327/327 - 3s - loss: 0.5596 - accuracy: 0.5238 - f1_score: 0.2439 - val_loss: 0.5716 - val_accuracy: 0.4103 - val_f1_score: 0.1450 - 3s/epoch - 10ms/step\n",
      "Epoch 9/80\n",
      "327/327 - 3s - loss: 0.5271 - accuracy: 0.5320 - f1_score: 0.2596 - val_loss: 0.5253 - val_accuracy: 0.4672 - val_f1_score: 0.1430 - 3s/epoch - 9ms/step\n",
      "Epoch 10/80\n",
      "327/327 - 3s - loss: 0.4974 - accuracy: 0.5268 - f1_score: 0.2580 - val_loss: 0.5117 - val_accuracy: 0.5276 - val_f1_score: 0.1340 - 3s/epoch - 9ms/step\n",
      "Epoch 11/80\n",
      "327/327 - 3s - loss: 0.4680 - accuracy: 0.5414 - f1_score: 0.2712 - val_loss: 0.4775 - val_accuracy: 0.4448 - val_f1_score: 0.1576 - 3s/epoch - 9ms/step\n",
      "Epoch 12/80\n",
      "327/327 - 3s - loss: 0.4421 - accuracy: 0.5500 - f1_score: 0.2932 - val_loss: 0.4747 - val_accuracy: 0.3672 - val_f1_score: 0.1348 - 3s/epoch - 10ms/step\n",
      "Epoch 13/80\n",
      "327/327 - 4s - loss: 0.4208 - accuracy: 0.5487 - f1_score: 0.2909 - val_loss: 0.4435 - val_accuracy: 0.4241 - val_f1_score: 0.1502 - 4s/epoch - 11ms/step\n",
      "Epoch 14/80\n",
      "327/327 - 7s - loss: 0.4041 - accuracy: 0.5469 - f1_score: 0.2923 - val_loss: 0.4378 - val_accuracy: 0.4707 - val_f1_score: 0.1497 - 7s/epoch - 21ms/step\n",
      "Epoch 15/80\n",
      "327/327 - 10s - loss: 0.3834 - accuracy: 0.5732 - f1_score: 0.3145 - val_loss: 0.4147 - val_accuracy: 0.4276 - val_f1_score: 0.1464 - 10s/epoch - 29ms/step\n",
      "Epoch 16/80\n",
      "327/327 - 10s - loss: 0.3682 - accuracy: 0.5707 - f1_score: 0.3143 - val_loss: 0.4153 - val_accuracy: 0.3948 - val_f1_score: 0.1449 - 10s/epoch - 30ms/step\n",
      "Epoch 17/80\n",
      "327/327 - 6s - loss: 0.3534 - accuracy: 0.5820 - f1_score: 0.3301 - val_loss: 0.4112 - val_accuracy: 0.4259 - val_f1_score: 0.1572 - 6s/epoch - 19ms/step\n",
      "Epoch 18/80\n",
      "327/327 - 9s - loss: 0.3397 - accuracy: 0.5816 - f1_score: 0.3336 - val_loss: 0.3823 - val_accuracy: 0.5207 - val_f1_score: 0.1312 - 9s/epoch - 26ms/step\n",
      "Epoch 19/80\n",
      "327/327 - 8s - loss: 0.3245 - accuracy: 0.6002 - f1_score: 0.3499 - val_loss: 0.3841 - val_accuracy: 0.5103 - val_f1_score: 0.1363 - 8s/epoch - 25ms/step\n",
      "Epoch 20/80\n",
      "327/327 - 8s - loss: 0.3169 - accuracy: 0.5870 - f1_score: 0.3425 - val_loss: 0.3706 - val_accuracy: 0.4276 - val_f1_score: 0.1445 - 8s/epoch - 24ms/step\n",
      "Epoch 21/80\n",
      "327/327 - 8s - loss: 0.3052 - accuracy: 0.6061 - f1_score: 0.3623 - val_loss: 0.3760 - val_accuracy: 0.4741 - val_f1_score: 0.1493 - 8s/epoch - 26ms/step\n",
      "Epoch 22/80\n",
      "327/327 - 10s - loss: 0.2986 - accuracy: 0.6015 - f1_score: 0.3636 - val_loss: 0.3344 - val_accuracy: 0.4759 - val_f1_score: 0.1502 - 10s/epoch - 30ms/step\n",
      "Epoch 23/80\n",
      "327/327 - 9s - loss: 0.2876 - accuracy: 0.6067 - f1_score: 0.3817 - val_loss: 0.3350 - val_accuracy: 0.4155 - val_f1_score: 0.1489 - 9s/epoch - 27ms/step\n",
      "Epoch 24/80\n",
      "327/327 - 9s - loss: 0.2805 - accuracy: 0.6098 - f1_score: 0.3784 - val_loss: 0.3385 - val_accuracy: 0.4552 - val_f1_score: 0.1494 - 9s/epoch - 26ms/step\n",
      "Epoch 25/80\n",
      "327/327 - 8s - loss: 0.2712 - accuracy: 0.6199 - f1_score: 0.3900 - val_loss: 0.3227 - val_accuracy: 0.4690 - val_f1_score: 0.1537 - 8s/epoch - 25ms/step\n",
      "Epoch 26/80\n",
      "327/327 - 9s - loss: 0.2683 - accuracy: 0.6029 - f1_score: 0.3740 - val_loss: 0.3351 - val_accuracy: 0.4534 - val_f1_score: 0.1513 - 9s/epoch - 26ms/step\n",
      "Epoch 27/80\n",
      "327/327 - 8s - loss: 0.2612 - accuracy: 0.6190 - f1_score: 0.4047 - val_loss: 0.3384 - val_accuracy: 0.4500 - val_f1_score: 0.1560 - 8s/epoch - 26ms/step\n",
      "Epoch 28/80\n",
      "327/327 - 8s - loss: 0.2551 - accuracy: 0.6209 - f1_score: 0.3944 - val_loss: 0.3084 - val_accuracy: 0.4603 - val_f1_score: 0.1506 - 8s/epoch - 24ms/step\n",
      "Epoch 29/80\n",
      "327/327 - 8s - loss: 0.2486 - accuracy: 0.6285 - f1_score: 0.4138 - val_loss: 0.3229 - val_accuracy: 0.5172 - val_f1_score: 0.1490 - 8s/epoch - 25ms/step\n",
      "Epoch 30/80\n",
      "327/327 - 8s - loss: 0.2442 - accuracy: 0.6333 - f1_score: 0.4110 - val_loss: 0.3292 - val_accuracy: 0.4397 - val_f1_score: 0.1513 - 8s/epoch - 25ms/step\n",
      "Epoch 31/80\n",
      "327/327 - 8s - loss: 0.2417 - accuracy: 0.6249 - f1_score: 0.4094 - val_loss: 0.2996 - val_accuracy: 0.4138 - val_f1_score: 0.1575 - 8s/epoch - 24ms/step\n",
      "Epoch 32/80\n",
      "327/327 - 8s - loss: 0.2359 - accuracy: 0.6381 - f1_score: 0.4137 - val_loss: 0.3267 - val_accuracy: 0.4759 - val_f1_score: 0.1387 - 8s/epoch - 25ms/step\n",
      "Epoch 33/80\n",
      "327/327 - 9s - loss: 0.2333 - accuracy: 0.6307 - f1_score: 0.4184 - val_loss: 0.2996 - val_accuracy: 0.3914 - val_f1_score: 0.1416 - 9s/epoch - 26ms/step\n",
      "Epoch 34/80\n",
      "327/327 - 8s - loss: 0.2280 - accuracy: 0.6421 - f1_score: 0.4332 - val_loss: 0.2958 - val_accuracy: 0.5000 - val_f1_score: 0.1857 - 8s/epoch - 24ms/step\n",
      "Epoch 35/80\n",
      "327/327 - 8s - loss: 0.2252 - accuracy: 0.6393 - f1_score: 0.4386 - val_loss: 0.3012 - val_accuracy: 0.5293 - val_f1_score: 0.1368 - 8s/epoch - 25ms/step\n",
      "Epoch 36/80\n",
      "327/327 - 8s - loss: 0.2216 - accuracy: 0.6481 - f1_score: 0.4401 - val_loss: 0.2998 - val_accuracy: 0.5172 - val_f1_score: 0.1226 - 8s/epoch - 24ms/step\n",
      "Epoch 37/80\n",
      "327/327 - 8s - loss: 0.2183 - accuracy: 0.6456 - f1_score: 0.4448 - val_loss: 0.3028 - val_accuracy: 0.4586 - val_f1_score: 0.1528 - 8s/epoch - 25ms/step\n",
      "Epoch 38/80\n",
      "327/327 - 8s - loss: 0.2153 - accuracy: 0.6548 - f1_score: 0.4535 - val_loss: 0.2984 - val_accuracy: 0.3948 - val_f1_score: 0.1458 - 8s/epoch - 26ms/step\n",
      "Epoch 39/80\n",
      "327/327 - 8s - loss: 0.2124 - accuracy: 0.6646 - f1_score: 0.4752 - val_loss: 0.3077 - val_accuracy: 0.4603 - val_f1_score: 0.1602 - 8s/epoch - 24ms/step\n",
      "Epoch 40/80\n",
      "327/327 - 8s - loss: 0.2100 - accuracy: 0.6575 - f1_score: 0.4499 - val_loss: 0.2884 - val_accuracy: 0.5121 - val_f1_score: 0.1675 - 8s/epoch - 25ms/step\n",
      "Epoch 41/80\n",
      "327/327 - 8s - loss: 0.2095 - accuracy: 0.6579 - f1_score: 0.4591 - val_loss: 0.2920 - val_accuracy: 0.4310 - val_f1_score: 0.1410 - 8s/epoch - 25ms/step\n",
      "Epoch 42/80\n",
      "327/327 - 8s - loss: 0.2081 - accuracy: 0.6511 - f1_score: 0.4537 - val_loss: 0.2880 - val_accuracy: 0.3879 - val_f1_score: 0.1431 - 8s/epoch - 24ms/step\n",
      "Epoch 43/80\n",
      "327/327 - 8s - loss: 0.2037 - accuracy: 0.6630 - f1_score: 0.4845 - val_loss: 0.2916 - val_accuracy: 0.4776 - val_f1_score: 0.1601 - 8s/epoch - 26ms/step\n",
      "Epoch 44/80\n",
      "327/327 - 9s - loss: 0.2032 - accuracy: 0.6573 - f1_score: 0.4647 - val_loss: 0.2935 - val_accuracy: 0.4793 - val_f1_score: 0.1439 - 9s/epoch - 28ms/step\n",
      "Epoch 45/80\n",
      "327/327 - 10s - loss: 0.2007 - accuracy: 0.6625 - f1_score: 0.4725 - val_loss: 0.2977 - val_accuracy: 0.4397 - val_f1_score: 0.1594 - 10s/epoch - 31ms/step\n",
      "Epoch 46/80\n",
      "327/327 - 10s - loss: 0.1966 - accuracy: 0.6749 - f1_score: 0.4762 - val_loss: 0.2992 - val_accuracy: 0.3552 - val_f1_score: 0.1382 - 10s/epoch - 32ms/step\n",
      "Epoch 47/80\n",
      "327/327 - 9s - loss: 0.1956 - accuracy: 0.6640 - f1_score: 0.4743 - val_loss: 0.2876 - val_accuracy: 0.4672 - val_f1_score: 0.1389 - 9s/epoch - 28ms/step\n",
      "Epoch 48/80\n",
      "327/327 - 9s - loss: 0.1952 - accuracy: 0.6657 - f1_score: 0.4798 - val_loss: 0.2982 - val_accuracy: 0.4966 - val_f1_score: 0.1312 - 9s/epoch - 26ms/step\n",
      "Epoch 49/80\n",
      "327/327 - 8s - loss: 0.1939 - accuracy: 0.6705 - f1_score: 0.4849 - val_loss: 0.2973 - val_accuracy: 0.4845 - val_f1_score: 0.1484 - 8s/epoch - 25ms/step\n",
      "Epoch 50/80\n",
      "327/327 - 8s - loss: 0.1913 - accuracy: 0.6803 - f1_score: 0.4895 - val_loss: 0.2921 - val_accuracy: 0.4759 - val_f1_score: 0.1441 - 8s/epoch - 25ms/step\n",
      "Epoch 51/80\n",
      "327/327 - 9s - loss: 0.1910 - accuracy: 0.6657 - f1_score: 0.4795 - val_loss: 0.2903 - val_accuracy: 0.3931 - val_f1_score: 0.1437 - 9s/epoch - 27ms/step\n",
      "Epoch 52/80\n",
      "327/327 - 8s - loss: 0.1907 - accuracy: 0.6653 - f1_score: 0.4857 - val_loss: 0.2966 - val_accuracy: 0.4293 - val_f1_score: 0.1700 - 8s/epoch - 26ms/step\n",
      "Epoch 53/80\n",
      "327/327 - 8s - loss: 0.1883 - accuracy: 0.6787 - f1_score: 0.4910 - val_loss: 0.2860 - val_accuracy: 0.4690 - val_f1_score: 0.1446 - 8s/epoch - 24ms/step\n",
      "Epoch 54/80\n",
      "327/327 - 8s - loss: 0.1866 - accuracy: 0.6833 - f1_score: 0.5111 - val_loss: 0.2909 - val_accuracy: 0.3879 - val_f1_score: 0.1504 - 8s/epoch - 26ms/step\n",
      "Epoch 55/80\n",
      "327/327 - 8s - loss: 0.1889 - accuracy: 0.6705 - f1_score: 0.4830 - val_loss: 0.2803 - val_accuracy: 0.5207 - val_f1_score: 0.1353 - 8s/epoch - 26ms/step\n",
      "Epoch 56/80\n",
      "327/327 - 8s - loss: 0.1862 - accuracy: 0.6730 - f1_score: 0.4930 - val_loss: 0.2721 - val_accuracy: 0.5190 - val_f1_score: 0.1452 - 8s/epoch - 24ms/step\n",
      "Epoch 57/80\n",
      "327/327 - 8s - loss: 0.1851 - accuracy: 0.6799 - f1_score: 0.4906 - val_loss: 0.2743 - val_accuracy: 0.4655 - val_f1_score: 0.1385 - 8s/epoch - 25ms/step\n",
      "Epoch 58/80\n",
      "327/327 - 8s - loss: 0.1827 - accuracy: 0.6808 - f1_score: 0.5048 - val_loss: 0.3174 - val_accuracy: 0.4155 - val_f1_score: 0.1378 - 8s/epoch - 25ms/step\n",
      "Epoch 59/80\n",
      "327/327 - 8s - loss: 0.1819 - accuracy: 0.6849 - f1_score: 0.5089 - val_loss: 0.3092 - val_accuracy: 0.3362 - val_f1_score: 0.1312 - 8s/epoch - 23ms/step\n",
      "Epoch 60/80\n",
      "327/327 - 8s - loss: 0.1822 - accuracy: 0.6881 - f1_score: 0.5103 - val_loss: 0.2843 - val_accuracy: 0.4672 - val_f1_score: 0.1513 - 8s/epoch - 25ms/step\n",
      "Epoch 61/80\n",
      "327/327 - 8s - loss: 0.1800 - accuracy: 0.6847 - f1_score: 0.5168 - val_loss: 0.2971 - val_accuracy: 0.5121 - val_f1_score: 0.1413 - 8s/epoch - 24ms/step\n",
      "Epoch 62/80\n",
      "327/327 - 9s - loss: 0.1798 - accuracy: 0.6948 - f1_score: 0.5186 - val_loss: 0.3493 - val_accuracy: 0.5017 - val_f1_score: 0.1243 - 9s/epoch - 27ms/step\n",
      "Epoch 63/80\n",
      "327/327 - 10s - loss: 0.1777 - accuracy: 0.6923 - f1_score: 0.5163 - val_loss: 0.2802 - val_accuracy: 0.4845 - val_f1_score: 0.1528 - 10s/epoch - 30ms/step\n",
      "Epoch 64/80\n",
      "327/327 - 9s - loss: 0.1780 - accuracy: 0.7008 - f1_score: 0.5265 - val_loss: 0.2961 - val_accuracy: 0.5224 - val_f1_score: 0.1484 - 9s/epoch - 29ms/step\n",
      "Epoch 65/80\n",
      "327/327 - 10s - loss: 0.1777 - accuracy: 0.6898 - f1_score: 0.5093 - val_loss: 0.2654 - val_accuracy: 0.4207 - val_f1_score: 0.1592 - 10s/epoch - 31ms/step\n",
      "Epoch 66/80\n",
      "327/327 - 11s - loss: 0.1769 - accuracy: 0.6874 - f1_score: 0.5087 - val_loss: 0.3009 - val_accuracy: 0.4397 - val_f1_score: 0.1624 - 11s/epoch - 33ms/step\n",
      "Epoch 67/80\n",
      "327/327 - 14s - loss: 0.1757 - accuracy: 0.7010 - f1_score: 0.5277 - val_loss: 0.2760 - val_accuracy: 0.4931 - val_f1_score: 0.1422 - 14s/epoch - 44ms/step\n",
      "Epoch 68/80\n",
      "327/327 - 15s - loss: 0.1747 - accuracy: 0.7010 - f1_score: 0.5320 - val_loss: 0.2818 - val_accuracy: 0.4466 - val_f1_score: 0.1511 - 15s/epoch - 47ms/step\n",
      "Epoch 69/80\n",
      "327/327 - 13s - loss: 0.1761 - accuracy: 0.7004 - f1_score: 0.5207 - val_loss: 0.2830 - val_accuracy: 0.4828 - val_f1_score: 0.1481 - 13s/epoch - 40ms/step\n",
      "Epoch 70/80\n",
      "327/327 - 12s - loss: 0.1744 - accuracy: 0.7011 - f1_score: 0.5349 - val_loss: 0.2761 - val_accuracy: 0.4103 - val_f1_score: 0.1595 - 12s/epoch - 36ms/step\n",
      "Epoch 71/80\n",
      "327/327 - 16s - loss: 0.1739 - accuracy: 0.7063 - f1_score: 0.5317 - val_loss: 0.2585 - val_accuracy: 0.4362 - val_f1_score: 0.1988 - 16s/epoch - 48ms/step\n",
      "Epoch 72/80\n",
      "327/327 - 14s - loss: 0.1754 - accuracy: 0.6875 - f1_score: 0.5095 - val_loss: 0.2948 - val_accuracy: 0.3517 - val_f1_score: 0.1499 - 14s/epoch - 44ms/step\n",
      "Epoch 73/80\n",
      "327/327 - 14s - loss: 0.1714 - accuracy: 0.7144 - f1_score: 0.5349 - val_loss: 0.2765 - val_accuracy: 0.5069 - val_f1_score: 0.1541 - 14s/epoch - 41ms/step\n",
      "Epoch 74/80\n",
      "327/327 - 14s - loss: 0.1713 - accuracy: 0.7096 - f1_score: 0.5402 - val_loss: 0.2786 - val_accuracy: 0.4362 - val_f1_score: 0.1433 - 14s/epoch - 44ms/step\n",
      "Epoch 75/80\n",
      "327/327 - 13s - loss: 0.1728 - accuracy: 0.6996 - f1_score: 0.5278 - val_loss: 0.2940 - val_accuracy: 0.4914 - val_f1_score: 0.1329 - 13s/epoch - 39ms/step\n",
      "Epoch 76/80\n",
      "327/327 - 14s - loss: 0.1715 - accuracy: 0.7036 - f1_score: 0.5248 - val_loss: 0.2944 - val_accuracy: 0.5052 - val_f1_score: 0.1503 - 14s/epoch - 44ms/step\n",
      "Epoch 77/80\n",
      "327/327 - 15s - loss: 0.1701 - accuracy: 0.7123 - f1_score: 0.5529 - val_loss: 0.2950 - val_accuracy: 0.4897 - val_f1_score: 0.1306 - 15s/epoch - 45ms/step\n",
      "Epoch 78/80\n",
      "327/327 - 13s - loss: 0.1702 - accuracy: 0.7090 - f1_score: 0.5369 - val_loss: 0.2843 - val_accuracy: 0.4707 - val_f1_score: 0.1486 - 13s/epoch - 40ms/step\n",
      "Epoch 79/80\n",
      "327/327 - 14s - loss: 0.1693 - accuracy: 0.7125 - f1_score: 0.5436 - val_loss: 0.2910 - val_accuracy: 0.3966 - val_f1_score: 0.1475 - 14s/epoch - 44ms/step\n",
      "Epoch 80/80\n",
      "327/327 - 14s - loss: 0.1675 - accuracy: 0.7215 - f1_score: 0.5584 - val_loss: 0.2874 - val_accuracy: 0.3897 - val_f1_score: 0.1476 - 14s/epoch - 42ms/step\n",
      "19/19 [==============================] - 3s 13ms/step\n",
      "19/19 [==============================] - 3s 23ms/step\n",
      "\n",
      "📋 Classification Report (Modelo 3 DES):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.63      0.73      0.68       310\n",
      "           D       0.46      0.45      0.45       167\n",
      "           G       1.00      0.08      0.14        26\n",
      "           C       0.84      0.72      0.78        29\n",
      "           A       0.67      0.08      0.15        24\n",
      "           M       0.77      0.96      0.85        24\n",
      "\n",
      "    accuracy                           0.60       580\n",
      "   macro avg       0.73      0.50      0.51       580\n",
      "weighted avg       0.62      0.60      0.58       580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === MODELO 3 - DESBALANCEADO con MIXUP y ENSEMBLE ===\n",
    "\n",
    "import os, sys, cv2, numpy as np, pandas as pd, torch, argparse\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.metrics import precision_recall_curve, classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from tensorflow.keras.applications import EfficientNetB3, efficientnet\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# --- Configuración general ---\n",
    "IMG_SIZE     = 224\n",
    "BATCH_SIZE   = 16\n",
    "EPOCHS       = 80\n",
    "ENSEMBLE_W   = 0.7\n",
    "LABEL_SMOOTH = 0.1\n",
    "LABELS = ['N', 'D', 'G', 'C', 'A', 'M']\n",
    "LABEL_MAP = {c: i for i, c in enumerate(LABELS)}\n",
    "\n",
    "# --- MixUp ---\n",
    "def mixup(x, y, alpha=0.2):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    idx = np.random.permutation(len(x))\n",
    "    return lam * x + (1 - lam) * x[idx], lam * y + (1 - lam) * y[idx]\n",
    "\n",
    "# --- Carga de CSV ---\n",
    "train_df = pd.read_csv(\"C:/Users/34629/TFG/train_DES.csv\")\n",
    "val_df = pd.read_csv(\"C:/Users/34629/TFG/val_DES.csv\")\n",
    "train_paths = train_df['Image_Path'].tolist()\n",
    "val_paths = val_df['Image_Path'].tolist()\n",
    "y_tr = train_df['class_label'].map(LABEL_MAP).values\n",
    "y_vl = val_df['class_label'].map(LABEL_MAP).values\n",
    "\n",
    "# --- Cargar o Extraer Características ---\n",
    "# RETFound\n",
    "X1_tr_path = \"C:/Users/34629/Downloads/X_rf_train_DES.npy\"\n",
    "X1_vl_path = \"C:/Users/34629/Downloads/X_rf_val_DES.npy\"\n",
    "y_tr_path = \"C:/Users/34629/Downloads/y_train_DES.npy\"\n",
    "y_vl_path = \"C:/Users/34629/Downloads/y_val_DES.npy\"\n",
    "\n",
    "# EfficientNet\n",
    "X2_tr_path = \"C:/Users/34629/Downloads/X_eff_train_DES.npy\"\n",
    "X2_vl_path = \"C:/Users/34629/Downloads/X_eff_val_DES.npy\"\n",
    "\n",
    "# Funciones de extracción\n",
    "sys.path.append(r\"C:/Users/34629/Downloads/RETFound_MAE\")\n",
    "from models_vit import RETFound_mae\n",
    "from util.pos_embed import interpolate_pos_embed\n",
    "\n",
    "torch.serialization.add_safe_globals([argparse.Namespace])\n",
    "\n",
    "def extract_retfound_features(paths, weights_path):\n",
    "    model = RETFound_mae(global_pool=True, img_size=IMG_SIZE)\n",
    "    ckpt = torch.load(weights_path, map_location='cpu', weights_only=False)\n",
    "    sd = ckpt['model']\n",
    "    sd.pop('head.weight', None); sd.pop('head.bias', None)\n",
    "    interpolate_pos_embed(model, sd)\n",
    "    model.load_state_dict(sd, strict=False)\n",
    "    model.eval()\n",
    "    feats = []\n",
    "    for p in tqdm(paths, desc=\"RETFound feats\"):\n",
    "        img = cv2.resize(cv2.imread(p), (IMG_SIZE, IMG_SIZE)) / 255.0\n",
    "        x = torch.from_numpy(img.astype('float32')).permute(2,0,1).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            f = model.forward_features(x).cpu().numpy().squeeze()\n",
    "        feats.append(f)\n",
    "    return np.stack(feats)\n",
    "\n",
    "def extract_eff_features(paths):\n",
    "    model = EfficientNetB3(include_top=False, pooling='avg', weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    feats = []\n",
    "    for p in tqdm(paths, desc=\"EffNet feats\"):\n",
    "        img = cv2.resize(cv2.imread(p), (IMG_SIZE, IMG_SIZE))\n",
    "        x = efficientnet.preprocess_input(img.astype('float32'))\n",
    "        feats.append(model(np.expand_dims(x, 0), training=False).numpy().squeeze())\n",
    "    return np.stack(feats)\n",
    "\n",
    "# RETFound\n",
    "if all(os.path.exists(p) for p in [X1_tr_path, X1_vl_path, y_tr_path, y_vl_path]):\n",
    "    X1_tr = np.load(X1_tr_path); X1_vl = np.load(X1_vl_path)\n",
    "    y_tr = np.load(y_tr_path); y_vl = np.load(y_vl_path)\n",
    "else:\n",
    "    X1_tr = extract_retfound_features(train_paths, \"C:/Users/34629/Downloads/RETFound_MAE/RETFound_cfp_weights.pth\")\n",
    "    X1_vl = extract_retfound_features(val_paths, \"C:/Users/34629/Downloads/RETFound_MAE/RETFound_cfp_weights.pth\")\n",
    "    np.save(X1_tr_path, X1_tr); np.save(X1_vl_path, X1_vl)\n",
    "    np.save(y_tr_path, y_tr); np.save(y_vl_path, y_vl)\n",
    "\n",
    "# EfficientNet\n",
    "if all(os.path.exists(p) for p in [X2_tr_path, X2_vl_path]):\n",
    "    X2_tr = np.load(X2_tr_path); X2_vl = np.load(X2_vl_path)\n",
    "else:\n",
    "    X2_tr = extract_eff_features(train_paths)\n",
    "    X2_vl = extract_eff_features(val_paths)\n",
    "    np.save(X2_tr_path, X2_tr); np.save(X2_vl_path, X2_vl)\n",
    "\n",
    "# --- One-hot y suavizado ---\n",
    "y_tr_cat = to_categorical(y_tr, num_classes=len(LABELS))\n",
    "y_vl_cat = to_categorical(y_vl, num_classes=len(LABELS))\n",
    "y_tr_cat = y_tr_cat * (1 - LABEL_SMOOTH) + LABEL_SMOOTH / len(LABELS)\n",
    "\n",
    "# --- MixUp en RETFound ---\n",
    "X1_tr, y_tr_cat = mixup(X1_tr, y_tr_cat)\n",
    "\n",
    "\n",
    "# --- Modelos ---\n",
    "\n",
    "def categorical_focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def loss(y_true, y_pred):\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "        weight = alpha * K.pow(1 - y_pred, gamma)\n",
    "        loss = weight * cross_entropy\n",
    "        return K.sum(loss, axis=-1)\n",
    "    return loss\n",
    "\n",
    "\n",
    "inp1 = Input((X1_tr.shape[1],))\n",
    "x = Dense(1024, kernel_regularizer=tf.keras.regularizers.l2(1e-3))(inp1)\n",
    "x = BatchNormalization()(x); x = LeakyReLU(0.1)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, kernel_regularizer=tf.keras.regularizers.l2(1e-3))(x)\n",
    "x = BatchNormalization()(x); x = LeakyReLU(0.1)(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(256, kernel_regularizer=tf.keras.regularizers.l2(1e-3))(x)\n",
    "x = BatchNormalization()(x); x = LeakyReLU(0.1)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "out1 = Dense(len(LABELS), activation='softmax')(x)\n",
    "m1 = Model(inp1, out1)\n",
    "\n",
    "inp2 = Input((X2_tr.shape[1],))\n",
    "y_ = Dense(512, kernel_regularizer=tf.keras.regularizers.l2(1e-3))(inp2)\n",
    "y_ = BatchNormalization()(y_); y_ = LeakyReLU(0.1)(y_); y_ = Dropout(0.4)(y_)\n",
    "out2 = Dense(len(LABELS), activation='softmax')(y_)\n",
    "m2 = Model(inp2, out2)\n",
    "\n",
    "loss_fn = categorical_focal_loss(gamma=2.0, alpha=0.25)\n",
    "\n",
    "m1.compile(optimizer=Adam(1e-4), loss=loss_fn,\n",
    "           metrics=['accuracy', tfa.metrics.F1Score(num_classes=len(LABELS), average='macro')])\n",
    "\n",
    "m2.compile(optimizer=Adam(1e-4), loss=loss_fn,\n",
    "           metrics=['accuracy', tfa.metrics.F1Score(num_classes=len(LABELS), average='macro')])\n",
    "\n",
    "m1.fit(X1_tr, y_tr_cat, validation_data=(X1_vl, y_vl_cat), epochs=EPOCHS,\n",
    "       batch_size=BATCH_SIZE, verbose=2)\n",
    "m2.fit(X2_tr, y_tr_cat, validation_data=(X2_vl, y_vl_cat), epochs=EPOCHS,\n",
    "       batch_size=BATCH_SIZE, verbose=2)\n",
    "\n",
    "# --- Ensemble e inferencia ---\n",
    "p1 = m1.predict(X1_vl)\n",
    "p2 = m2.predict(X2_vl)\n",
    "probs = ENSEMBLE_W * p1 + (1 - ENSEMBLE_W) * p2\n",
    "y_true = y_vl\n",
    "\n",
    "# --- Ajuste de umbrales ---\n",
    "THRESH = np.ones(len(LABELS)) * 0.5\n",
    "y_vl_bin = label_binarize(y_true, classes=np.arange(len(LABELS)))\n",
    "for i in range(len(LABELS)):\n",
    "    prec, rec, thr = precision_recall_curve((y_true == i).astype(int), probs[:, i])\n",
    "    F = 2 * prec * rec / (prec + rec + 1e-8)\n",
    "    THRESH[i] = thr[np.nanargmax(F)]\n",
    "\n",
    "y_pred = []\n",
    "for row in probs:\n",
    "    sel = np.where(row >= THRESH)[0]\n",
    "    if len(sel) == 1: y_pred.append(sel[0])\n",
    "    elif len(sel) > 1: y_pred.append(sel[np.argmax(row[sel])])\n",
    "    else: y_pred.append(int(np.argmax(row)))\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# --- Reporte ---\n",
    "print(\"\\n📋 Classification Report (Modelo 3 DES):\")\n",
    "print(classification_report(y_true, y_pred, target_names=LABELS))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=LABELS, yticklabels=LABELS)\n",
    "plt.title(\"Matriz de Confusión - Modelo 3 DES\")\n",
    "plt.savefig(\"matriz_confusion_modelo3_DES.png\"); plt.close()\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "for i in range(len(LABELS)):\n",
    "    fpr, tpr, _ = roc_curve(y_vl_bin[:, i], probs[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f\"{LABELS[i]} (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\")\n",
    "plt.title(\"Curvas ROC - Modelo 3 DES\")\n",
    "plt.legend(); plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"curva_ROC_modelo3_DES.png\"); plt.close()\n",
    "\n",
    "# --- Grad-CAM ---\n",
    "def generar_gradcam(img_path, nombre_archivo):\n",
    "    ret_model = RETFound_mae(global_pool=False, img_size=IMG_SIZE)\n",
    "    ckpt = torch.load(\"C:/Users/34629/Downloads/RETFound_MAE/RETFound_cfp_weights.pth\", map_location='cpu')\n",
    "    sd = ckpt['model']\n",
    "    sd.pop('head.weight', None); sd.pop('head.bias', None)\n",
    "    interpolate_pos_embed(ret_model, sd)\n",
    "    ret_model.load_state_dict(sd, strict=False); ret_model.eval()\n",
    "    activations = {}\n",
    "    ret_model.blocks[11].register_forward_hook(lambda m, i, o: activations.update({'value': o}))\n",
    "    img = Image.open(img_path).convert('RGB').resize((IMG_SIZE, IMG_SIZE))\n",
    "    x = transforms.ToTensor()(img).unsqueeze(0)\n",
    "    with torch.no_grad(): ret_model(x)\n",
    "    cam = activations['value'].squeeze(0).numpy()[1:].mean(axis=1).reshape(14, 14)\n",
    "    cam = cv2.resize((cam - cam.min()) / (cam.max() - cam.min()), (IMG_SIZE, IMG_SIZE))\n",
    "    cam = np.uint8(255 * cam); cam_color = cv2.applyColorMap(cam, cv2.COLORMAP_JET)\n",
    "    superpuesta = 0.4 * np.array(img) + 0.6 * cam_color\n",
    "    cv2.imwrite(nombre_archivo, cv2.cvtColor(np.uint8(superpuesta), cv2.COLOR_RGB2BGR))\n",
    "\n",
    "# Una imagen correcta y una errónea\n",
    "df_res = pd.DataFrame({'img': val_paths[:len(y_true)], 'true': y_true, 'pred': y_pred})\n",
    "df_res['correcto'] = df_res['true'] == df_res['pred']\n",
    "bien = df_res[df_res['correcto']].iloc[0]\n",
    "mal = df_res[~df_res['correcto']].iloc[0]\n",
    "\n",
    "generar_gradcam(bien['img'], f\"gradcam_modelo3_DES_correcto_{LABELS[bien['pred']]}.png\")\n",
    "generar_gradcam(mal['img'], f\"gradcam_modelo3_DES_error_{LABELS[mal['true']]}_pred{LABELS[mal['pred']]}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "876f0605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "1047/1047 - 180s - loss: 0.2846 - accuracy: 0.4279 - f1: 0.3295 - val_loss: 0.2702 - val_accuracy: 0.3845 - val_f1: 0.4131 - 180s/epoch - 172ms/step\n",
      "Epoch 2/80\n",
      "1047/1047 - 98s - loss: 0.2371 - accuracy: 0.5014 - f1: 0.3796 - val_loss: 0.2618 - val_accuracy: 0.3897 - val_f1: 0.4342 - 98s/epoch - 94ms/step\n",
      "Epoch 3/80\n",
      "1047/1047 - 98s - loss: 0.2203 - accuracy: 0.5313 - f1: 0.3992 - val_loss: 0.2691 - val_accuracy: 0.3690 - val_f1: 0.4342 - 98s/epoch - 94ms/step\n",
      "Epoch 4/80\n",
      "1047/1047 - 94s - loss: 0.2092 - accuracy: 0.5592 - f1: 0.4157 - val_loss: 0.2493 - val_accuracy: 0.3741 - val_f1: 0.4200 - 94s/epoch - 90ms/step\n",
      "Epoch 5/80\n",
      "1047/1047 - 101s - loss: 0.2015 - accuracy: 0.5812 - f1: 0.4306 - val_loss: 0.2451 - val_accuracy: 0.3931 - val_f1: 0.4563 - 101s/epoch - 96ms/step\n",
      "Epoch 6/80\n",
      "1047/1047 - 93s - loss: 0.1933 - accuracy: 0.6149 - f1: 0.4507 - val_loss: 0.2499 - val_accuracy: 0.3741 - val_f1: 0.4440 - 93s/epoch - 89ms/step\n",
      "Epoch 7/80\n",
      "1047/1047 - 97s - loss: 0.1889 - accuracy: 0.6295 - f1: 0.4576 - val_loss: 0.2275 - val_accuracy: 0.4069 - val_f1: 0.4455 - 97s/epoch - 92ms/step\n",
      "Epoch 8/80\n",
      "1047/1047 - 96s - loss: 0.1834 - accuracy: 0.6534 - f1: 0.4733 - val_loss: 0.2234 - val_accuracy: 0.4483 - val_f1: 0.4906 - 96s/epoch - 92ms/step\n",
      "Epoch 9/80\n",
      "1047/1047 - 93s - loss: 0.1789 - accuracy: 0.6732 - f1: 0.4859 - val_loss: 0.2225 - val_accuracy: 0.4414 - val_f1: 0.4834 - 93s/epoch - 89ms/step\n",
      "Epoch 10/80\n",
      "1047/1047 - 89s - loss: 0.1761 - accuracy: 0.6825 - f1: 0.4919 - val_loss: 0.2261 - val_accuracy: 0.4259 - val_f1: 0.4649 - 89s/epoch - 85ms/step\n",
      "Epoch 11/80\n",
      "1047/1047 - 84s - loss: 0.1726 - accuracy: 0.6997 - f1: 0.5037 - val_loss: 0.2268 - val_accuracy: 0.4397 - val_f1: 0.4775 - 84s/epoch - 80ms/step\n",
      "Epoch 12/80\n",
      "1047/1047 - 84s - loss: 0.1694 - accuracy: 0.7120 - f1: 0.5109 - val_loss: 0.2226 - val_accuracy: 0.4448 - val_f1: 0.4940 - 84s/epoch - 80ms/step\n",
      "Epoch 13/80\n",
      "1047/1047 - 84s - loss: 0.1672 - accuracy: 0.7191 - f1: 0.5162 - val_loss: 0.2840 - val_accuracy: 0.3310 - val_f1: 0.4461 - 84s/epoch - 80ms/step\n",
      "Epoch 14/80\n",
      "1047/1047 - 85s - loss: 0.1651 - accuracy: 0.7271 - f1: 0.5198 - val_loss: 0.2061 - val_accuracy: 0.4862 - val_f1: 0.5254 - 85s/epoch - 81ms/step\n",
      "Epoch 15/80\n",
      "1047/1047 - 84s - loss: 0.1621 - accuracy: 0.7415 - f1: 0.5293 - val_loss: 0.2411 - val_accuracy: 0.4293 - val_f1: 0.4797 - 84s/epoch - 80ms/step\n",
      "Epoch 16/80\n",
      "1047/1047 - 85s - loss: 0.1610 - accuracy: 0.7440 - f1: 0.5318 - val_loss: 0.2398 - val_accuracy: 0.4310 - val_f1: 0.4805 - 85s/epoch - 82ms/step\n",
      "Epoch 17/80\n",
      "1047/1047 - 60s - loss: 0.1578 - accuracy: 0.7594 - f1: 0.5422 - val_loss: 0.2580 - val_accuracy: 0.4224 - val_f1: 0.5122 - 60s/epoch - 57ms/step\n",
      "Epoch 18/80\n",
      "1047/1047 - 60s - loss: 0.1576 - accuracy: 0.7631 - f1: 0.5441 - val_loss: 0.1947 - val_accuracy: 0.5000 - val_f1: 0.5243 - 60s/epoch - 58ms/step\n",
      "Epoch 19/80\n",
      "1047/1047 - 58s - loss: 0.1559 - accuracy: 0.7661 - f1: 0.5456 - val_loss: 0.2001 - val_accuracy: 0.5052 - val_f1: 0.5205 - 58s/epoch - 56ms/step\n",
      "Epoch 20/80\n",
      "1047/1047 - 59s - loss: 0.1545 - accuracy: 0.7713 - f1: 0.5491 - val_loss: 0.1948 - val_accuracy: 0.5052 - val_f1: 0.5173 - 59s/epoch - 56ms/step\n",
      "Epoch 21/80\n",
      "1047/1047 - 60s - loss: 0.1530 - accuracy: 0.7753 - f1: 0.5527 - val_loss: 0.2028 - val_accuracy: 0.5190 - val_f1: 0.5321 - 60s/epoch - 57ms/step\n",
      "Epoch 22/80\n",
      "1047/1047 - 79s - loss: 0.1518 - accuracy: 0.7838 - f1: 0.5579 - val_loss: 0.2074 - val_accuracy: 0.4897 - val_f1: 0.5183 - 79s/epoch - 75ms/step\n",
      "Epoch 23/80\n",
      "1047/1047 - 85s - loss: 0.1504 - accuracy: 0.7869 - f1: 0.5591 - val_loss: 0.2264 - val_accuracy: 0.4741 - val_f1: 0.5157 - 85s/epoch - 81ms/step\n",
      "Epoch 24/80\n",
      "1047/1047 - 86s - loss: 0.1490 - accuracy: 0.7937 - f1: 0.5644 - val_loss: 0.1921 - val_accuracy: 0.5121 - val_f1: 0.5374 - 86s/epoch - 82ms/step\n",
      "Epoch 25/80\n",
      "1047/1047 - 82s - loss: 0.1478 - accuracy: 0.7965 - f1: 0.5662 - val_loss: 0.2076 - val_accuracy: 0.5224 - val_f1: 0.5465 - 82s/epoch - 78ms/step\n",
      "Epoch 26/80\n",
      "1047/1047 - 82s - loss: 0.1478 - accuracy: 0.7995 - f1: 0.5681 - val_loss: 0.1863 - val_accuracy: 0.5293 - val_f1: 0.5535 - 82s/epoch - 78ms/step\n",
      "Epoch 27/80\n",
      "1047/1047 - 82s - loss: 0.1465 - accuracy: 0.8030 - f1: 0.5710 - val_loss: 0.1912 - val_accuracy: 0.5379 - val_f1: 0.5611 - 82s/epoch - 78ms/step\n",
      "Epoch 28/80\n",
      "1047/1047 - 76s - loss: 0.1459 - accuracy: 0.8099 - f1: 0.5748 - val_loss: 0.1890 - val_accuracy: 0.5414 - val_f1: 0.5394 - 76s/epoch - 73ms/step\n",
      "Epoch 29/80\n",
      "1047/1047 - 71s - loss: 0.1448 - accuracy: 0.8107 - f1: 0.5763 - val_loss: 0.2159 - val_accuracy: 0.5172 - val_f1: 0.5249 - 71s/epoch - 68ms/step\n",
      "Epoch 30/80\n",
      "1047/1047 - 68s - loss: 0.1437 - accuracy: 0.8151 - f1: 0.5785 - val_loss: 0.2180 - val_accuracy: 0.5172 - val_f1: 0.5233 - 68s/epoch - 65ms/step\n",
      "Epoch 31/80\n",
      "1047/1047 - 70s - loss: 0.1425 - accuracy: 0.8173 - f1: 0.5802 - val_loss: 0.1955 - val_accuracy: 0.5466 - val_f1: 0.5479 - 70s/epoch - 67ms/step\n",
      "Epoch 32/80\n",
      "1047/1047 - 71s - loss: 0.1427 - accuracy: 0.8187 - f1: 0.5814 - val_loss: 0.1886 - val_accuracy: 0.5552 - val_f1: 0.5659 - 71s/epoch - 67ms/step\n",
      "Epoch 33/80\n",
      "1047/1047 - 70s - loss: 0.1414 - accuracy: 0.8233 - f1: 0.5847 - val_loss: 0.1944 - val_accuracy: 0.5603 - val_f1: 0.5782 - 70s/epoch - 66ms/step\n",
      "Epoch 34/80\n",
      "1047/1047 - 70s - loss: 0.1408 - accuracy: 0.8277 - f1: 0.5873 - val_loss: 0.2683 - val_accuracy: 0.4414 - val_f1: 0.4975 - 70s/epoch - 67ms/step\n",
      "Epoch 35/80\n",
      "1047/1047 - 70s - loss: 0.1397 - accuracy: 0.8298 - f1: 0.5882 - val_loss: 0.2101 - val_accuracy: 0.5379 - val_f1: 0.5664 - 70s/epoch - 66ms/step\n",
      "Epoch 36/80\n",
      "1047/1047 - 71s - loss: 0.1396 - accuracy: 0.8333 - f1: 0.5905 - val_loss: 0.1733 - val_accuracy: 0.6000 - val_f1: 0.5917 - 71s/epoch - 68ms/step\n",
      "Epoch 37/80\n",
      "1047/1047 - 71s - loss: 0.1383 - accuracy: 0.8348 - f1: 0.5912 - val_loss: 0.2007 - val_accuracy: 0.5517 - val_f1: 0.5743 - 71s/epoch - 67ms/step\n",
      "Epoch 38/80\n",
      "1047/1047 - 71s - loss: 0.1384 - accuracy: 0.8333 - f1: 0.5907 - val_loss: 0.1842 - val_accuracy: 0.5655 - val_f1: 0.5778 - 71s/epoch - 68ms/step\n",
      "Epoch 39/80\n",
      "1047/1047 - 70s - loss: 0.1378 - accuracy: 0.8385 - f1: 0.5941 - val_loss: 0.1867 - val_accuracy: 0.5638 - val_f1: 0.5809 - 70s/epoch - 66ms/step\n",
      "Epoch 40/80\n",
      "1047/1047 - 71s - loss: 0.1371 - accuracy: 0.8388 - f1: 0.5938 - val_loss: 0.2343 - val_accuracy: 0.4897 - val_f1: 0.5260 - 71s/epoch - 68ms/step\n",
      "Epoch 41/80\n",
      "1047/1047 - 70s - loss: 0.1371 - accuracy: 0.8387 - f1: 0.5947 - val_loss: 0.2011 - val_accuracy: 0.5414 - val_f1: 0.5757 - 70s/epoch - 67ms/step\n",
      "Epoch 42/80\n",
      "1047/1047 - 63s - loss: 0.1352 - accuracy: 0.8462 - f1: 0.5986 - val_loss: 0.1854 - val_accuracy: 0.5707 - val_f1: 0.6011 - 63s/epoch - 60ms/step\n",
      "Epoch 43/80\n",
      "1047/1047 - 61s - loss: 0.1364 - accuracy: 0.8441 - f1: 0.5972 - val_loss: 0.1805 - val_accuracy: 0.5966 - val_f1: 0.5657 - 61s/epoch - 58ms/step\n",
      "Epoch 44/80\n",
      "1047/1047 - 63s - loss: 0.1356 - accuracy: 0.8444 - f1: 0.5981 - val_loss: 0.2125 - val_accuracy: 0.5155 - val_f1: 0.5500 - 63s/epoch - 60ms/step\n",
      "Epoch 45/80\n",
      "1047/1047 - 63s - loss: 0.1333 - accuracy: 0.8520 - f1: 0.6035 - val_loss: 0.1824 - val_accuracy: 0.6379 - val_f1: 0.6068 - 63s/epoch - 61ms/step\n",
      "Epoch 46/80\n",
      "1047/1047 - 63s - loss: 0.1343 - accuracy: 0.8533 - f1: 0.6041 - val_loss: 0.1904 - val_accuracy: 0.5707 - val_f1: 0.5954 - 63s/epoch - 60ms/step\n",
      "Epoch 47/80\n",
      "1047/1047 - 65s - loss: 0.1334 - accuracy: 0.8522 - f1: 0.6031 - val_loss: 0.2193 - val_accuracy: 0.5034 - val_f1: 0.5526 - 65s/epoch - 62ms/step\n",
      "Epoch 48/80\n",
      "1047/1047 - 64s - loss: 0.1330 - accuracy: 0.8557 - f1: 0.6055 - val_loss: 0.2166 - val_accuracy: 0.5431 - val_f1: 0.5673 - 64s/epoch - 62ms/step\n",
      "Epoch 49/80\n",
      "1047/1047 - 65s - loss: 0.1328 - accuracy: 0.8545 - f1: 0.6051 - val_loss: 0.1871 - val_accuracy: 0.6069 - val_f1: 0.5985 - 65s/epoch - 62ms/step\n",
      "Epoch 50/80\n",
      "1047/1047 - 63s - loss: 0.1329 - accuracy: 0.8545 - f1: 0.6048 - val_loss: 0.1955 - val_accuracy: 0.5621 - val_f1: 0.5802 - 63s/epoch - 61ms/step\n",
      "Epoch 51/80\n",
      "1047/1047 - 65s - loss: 0.1315 - accuracy: 0.8606 - f1: 0.6085 - val_loss: 0.2108 - val_accuracy: 0.5431 - val_f1: 0.5709 - 65s/epoch - 62ms/step\n",
      "Epoch 52/80\n",
      "1047/1047 - 64s - loss: 0.1315 - accuracy: 0.8593 - f1: 0.6078 - val_loss: 0.2699 - val_accuracy: 0.4810 - val_f1: 0.5375 - 64s/epoch - 61ms/step\n",
      "Epoch 53/80\n",
      "1047/1047 - 65s - loss: 0.1308 - accuracy: 0.8642 - f1: 0.6108 - val_loss: 0.2039 - val_accuracy: 0.5397 - val_f1: 0.5486 - 65s/epoch - 62ms/step\n",
      "Epoch 54/80\n",
      "1047/1047 - 66s - loss: 0.1310 - accuracy: 0.8631 - f1: 0.6103 - val_loss: 0.2086 - val_accuracy: 0.5500 - val_f1: 0.5685 - 66s/epoch - 63ms/step\n",
      "Epoch 55/80\n",
      "1047/1047 - 64s - loss: 0.1297 - accuracy: 0.8667 - f1: 0.6133 - val_loss: 0.2112 - val_accuracy: 0.5534 - val_f1: 0.5611 - 64s/epoch - 61ms/step\n",
      "Epoch 56/80\n",
      "1047/1047 - 64s - loss: 0.1298 - accuracy: 0.8657 - f1: 0.6121 - val_loss: 0.2321 - val_accuracy: 0.5017 - val_f1: 0.5403 - 64s/epoch - 61ms/step\n",
      "Epoch 57/80\n",
      "1047/1047 - 64s - loss: 0.1296 - accuracy: 0.8652 - f1: 0.6114 - val_loss: 0.2105 - val_accuracy: 0.5328 - val_f1: 0.5737 - 64s/epoch - 61ms/step\n",
      "Epoch 58/80\n",
      "1047/1047 - 63s - loss: 0.1291 - accuracy: 0.8694 - f1: 0.6141 - val_loss: 0.2120 - val_accuracy: 0.5655 - val_f1: 0.5708 - 63s/epoch - 60ms/step\n",
      "Epoch 59/80\n",
      "1047/1047 - 64s - loss: 0.1288 - accuracy: 0.8702 - f1: 0.6144 - val_loss: 0.2212 - val_accuracy: 0.5466 - val_f1: 0.5878 - 64s/epoch - 61ms/step\n",
      "Epoch 60/80\n",
      "1047/1047 - 63s - loss: 0.1288 - accuracy: 0.8699 - f1: 0.6148 - val_loss: 0.1867 - val_accuracy: 0.6034 - val_f1: 0.6083 - 63s/epoch - 61ms/step\n",
      "Epoch 61/80\n",
      "1047/1047 - 63s - loss: 0.1276 - accuracy: 0.8731 - f1: 0.6168 - val_loss: 0.1960 - val_accuracy: 0.6000 - val_f1: 0.5966 - 63s/epoch - 60ms/step\n",
      "Epoch 62/80\n",
      "1047/1047 - 64s - loss: 0.1272 - accuracy: 0.8770 - f1: 0.6190 - val_loss: 0.2195 - val_accuracy: 0.5552 - val_f1: 0.5678 - 64s/epoch - 61ms/step\n",
      "Epoch 63/80\n",
      "1047/1047 - 63s - loss: 0.1274 - accuracy: 0.8737 - f1: 0.6169 - val_loss: 0.1989 - val_accuracy: 0.6017 - val_f1: 0.5772 - 63s/epoch - 60ms/step\n",
      "Epoch 64/80\n",
      "1047/1047 - 64s - loss: 0.1270 - accuracy: 0.8751 - f1: 0.6178 - val_loss: 0.1852 - val_accuracy: 0.5966 - val_f1: 0.5953 - 64s/epoch - 61ms/step\n",
      "Epoch 65/80\n",
      "1047/1047 - 63s - loss: 0.1272 - accuracy: 0.8764 - f1: 0.6182 - val_loss: 0.1943 - val_accuracy: 0.5931 - val_f1: 0.5967 - 63s/epoch - 60ms/step\n",
      "Epoch 66/80\n",
      "1047/1047 - 64s - loss: 0.1266 - accuracy: 0.8771 - f1: 0.6200 - val_loss: 0.1884 - val_accuracy: 0.6121 - val_f1: 0.6085 - 64s/epoch - 62ms/step\n",
      "Epoch 67/80\n",
      "1047/1047 - 63s - loss: 0.1263 - accuracy: 0.8794 - f1: 0.6215 - val_loss: 0.2151 - val_accuracy: 0.5431 - val_f1: 0.5727 - 63s/epoch - 60ms/step\n",
      "Epoch 68/80\n",
      "1047/1047 - 64s - loss: 0.1266 - accuracy: 0.8773 - f1: 0.6190 - val_loss: 0.2053 - val_accuracy: 0.5672 - val_f1: 0.5855 - 64s/epoch - 61ms/step\n",
      "Epoch 69/80\n",
      "1047/1047 - 55s - loss: 0.1256 - accuracy: 0.8806 - f1: 0.6215 - val_loss: 0.2048 - val_accuracy: 0.5741 - val_f1: 0.5859 - 55s/epoch - 53ms/step\n",
      "Epoch 70/80\n",
      "1047/1047 - 54s - loss: 0.1256 - accuracy: 0.8819 - f1: 0.6225 - val_loss: 0.1936 - val_accuracy: 0.5810 - val_f1: 0.5972 - 54s/epoch - 51ms/step\n",
      "Epoch 71/80\n",
      "1047/1047 - 67s - loss: 0.1247 - accuracy: 0.8814 - f1: 0.6226 - val_loss: 0.2190 - val_accuracy: 0.5448 - val_f1: 0.5658 - 67s/epoch - 64ms/step\n",
      "Epoch 72/80\n",
      "1047/1047 - 70s - loss: 0.1247 - accuracy: 0.8856 - f1: 0.6252 - val_loss: 0.2108 - val_accuracy: 0.5603 - val_f1: 0.5660 - 70s/epoch - 66ms/step\n",
      "Epoch 73/80\n",
      "1047/1047 - 69s - loss: 0.1243 - accuracy: 0.8865 - f1: 0.6255 - val_loss: 0.2138 - val_accuracy: 0.5448 - val_f1: 0.5805 - 69s/epoch - 66ms/step\n",
      "Epoch 74/80\n",
      "1047/1047 - 69s - loss: 0.1247 - accuracy: 0.8828 - f1: 0.6224 - val_loss: 0.1872 - val_accuracy: 0.6190 - val_f1: 0.6352 - 69s/epoch - 66ms/step\n",
      "Epoch 75/80\n",
      "1047/1047 - 69s - loss: 0.1243 - accuracy: 0.8847 - f1: 0.6241 - val_loss: 0.2057 - val_accuracy: 0.6069 - val_f1: 0.5972 - 69s/epoch - 66ms/step\n",
      "Epoch 76/80\n",
      "1047/1047 - 64s - loss: 0.1240 - accuracy: 0.8856 - f1: 0.6247 - val_loss: 0.1867 - val_accuracy: 0.6466 - val_f1: 0.6192 - 64s/epoch - 61ms/step\n",
      "Epoch 77/80\n",
      "1047/1047 - 60s - loss: 0.1232 - accuracy: 0.8887 - f1: 0.6269 - val_loss: 0.2185 - val_accuracy: 0.5431 - val_f1: 0.5645 - 60s/epoch - 57ms/step\n",
      "Epoch 78/80\n",
      "1047/1047 - 61s - loss: 0.1240 - accuracy: 0.8837 - f1: 0.6236 - val_loss: 0.1888 - val_accuracy: 0.6241 - val_f1: 0.6248 - 61s/epoch - 58ms/step\n",
      "Epoch 79/80\n",
      "1047/1047 - 60s - loss: 0.1234 - accuracy: 0.8894 - f1: 0.6273 - val_loss: 0.1955 - val_accuracy: 0.5914 - val_f1: 0.5893 - 60s/epoch - 58ms/step\n",
      "Epoch 80/80\n",
      "1047/1047 - 61s - loss: 0.1228 - accuracy: 0.8934 - f1: 0.6299 - val_loss: 0.2022 - val_accuracy: 0.6103 - val_f1: 0.5945 - 61s/epoch - 58ms/step\n",
      "Epoch 1/80\n",
      "327/327 - 35s - loss: 0.3578 - accuracy: 0.2962 - f1: 0.2793 - val_loss: 0.3072 - val_accuracy: 0.3586 - val_f1: 0.4240 - 35s/epoch - 106ms/step\n",
      "Epoch 2/80\n",
      "327/327 - 12s - loss: 0.2628 - accuracy: 0.4193 - f1: 0.3823 - val_loss: 0.3149 - val_accuracy: 0.4259 - val_f1: 0.4761 - 12s/epoch - 38ms/step\n",
      "Epoch 3/80\n",
      "327/327 - 13s - loss: 0.2192 - accuracy: 0.4460 - f1: 0.4162 - val_loss: 0.2607 - val_accuracy: 0.5603 - val_f1: 0.5271 - 13s/epoch - 41ms/step\n",
      "Epoch 4/80\n",
      "327/327 - 10s - loss: 0.2008 - accuracy: 0.4508 - f1: 0.4272 - val_loss: 0.2717 - val_accuracy: 0.5397 - val_f1: 0.5160 - 10s/epoch - 32ms/step\n",
      "Epoch 5/80\n",
      "327/327 - 10s - loss: 0.1838 - accuracy: 0.4851 - f1: 0.4512 - val_loss: 0.2811 - val_accuracy: 0.4914 - val_f1: 0.5039 - 10s/epoch - 29ms/step\n",
      "Epoch 6/80\n",
      "327/327 - 10s - loss: 0.1710 - accuracy: 0.5094 - f1: 0.4765 - val_loss: 0.2648 - val_accuracy: 0.5138 - val_f1: 0.5418 - 10s/epoch - 30ms/step\n",
      "Epoch 7/80\n",
      "327/327 - 10s - loss: 0.1622 - accuracy: 0.5161 - f1: 0.4802 - val_loss: 0.2947 - val_accuracy: 0.4379 - val_f1: 0.4838 - 10s/epoch - 30ms/step\n",
      "Epoch 8/80\n",
      "327/327 - 9s - loss: 0.1522 - accuracy: 0.5284 - f1: 0.4951 - val_loss: 0.3041 - val_accuracy: 0.4672 - val_f1: 0.5240 - 9s/epoch - 28ms/step\n",
      "Epoch 9/80\n",
      "327/327 - 10s - loss: 0.1497 - accuracy: 0.5381 - f1: 0.5045 - val_loss: 0.2259 - val_accuracy: 0.5552 - val_f1: 0.5646 - 10s/epoch - 32ms/step\n",
      "Epoch 10/80\n",
      "327/327 - 9s - loss: 0.1418 - accuracy: 0.5577 - f1: 0.5199 - val_loss: 0.2534 - val_accuracy: 0.5052 - val_f1: 0.5350 - 9s/epoch - 29ms/step\n",
      "Epoch 11/80\n",
      "327/327 - 10s - loss: 0.1316 - accuracy: 0.5651 - f1: 0.5266 - val_loss: 0.2427 - val_accuracy: 0.5224 - val_f1: 0.5373 - 10s/epoch - 32ms/step\n",
      "Epoch 12/80\n",
      "327/327 - 10s - loss: 0.1275 - accuracy: 0.5699 - f1: 0.5266 - val_loss: 0.2386 - val_accuracy: 0.5707 - val_f1: 0.5603 - 10s/epoch - 31ms/step\n",
      "Epoch 13/80\n",
      "327/327 - 10s - loss: 0.1173 - accuracy: 0.5929 - f1: 0.5471 - val_loss: 0.2218 - val_accuracy: 0.5672 - val_f1: 0.5694 - 10s/epoch - 30ms/step\n",
      "Epoch 14/80\n",
      "327/327 - 10s - loss: 0.1152 - accuracy: 0.6033 - f1: 0.5577 - val_loss: 0.2381 - val_accuracy: 0.5172 - val_f1: 0.5583 - 10s/epoch - 32ms/step\n",
      "Epoch 15/80\n",
      "327/327 - 11s - loss: 0.1099 - accuracy: 0.6102 - f1: 0.5616 - val_loss: 0.2454 - val_accuracy: 0.5483 - val_f1: 0.5563 - 11s/epoch - 35ms/step\n",
      "Epoch 16/80\n",
      "327/327 - 10s - loss: 0.1081 - accuracy: 0.6038 - f1: 0.5546 - val_loss: 0.2547 - val_accuracy: 0.5207 - val_f1: 0.5449 - 10s/epoch - 31ms/step\n",
      "Epoch 17/80\n",
      "327/327 - 11s - loss: 0.1014 - accuracy: 0.6324 - f1: 0.5809 - val_loss: 0.2360 - val_accuracy: 0.5586 - val_f1: 0.5524 - 11s/epoch - 32ms/step\n",
      "Epoch 18/80\n",
      "327/327 - 10s - loss: 0.1014 - accuracy: 0.6232 - f1: 0.5754 - val_loss: 0.2203 - val_accuracy: 0.5931 - val_f1: 0.6085 - 10s/epoch - 32ms/step\n",
      "Epoch 19/80\n",
      "327/327 - 10s - loss: 0.0953 - accuracy: 0.6460 - f1: 0.5923 - val_loss: 0.2186 - val_accuracy: 0.5897 - val_f1: 0.5867 - 10s/epoch - 30ms/step\n",
      "Epoch 20/80\n",
      "327/327 - 10s - loss: 0.0893 - accuracy: 0.6575 - f1: 0.6003 - val_loss: 0.2234 - val_accuracy: 0.5828 - val_f1: 0.5909 - 10s/epoch - 31ms/step\n",
      "Epoch 21/80\n",
      "327/327 - 11s - loss: 0.0863 - accuracy: 0.6703 - f1: 0.6083 - val_loss: 0.2231 - val_accuracy: 0.5914 - val_f1: 0.6012 - 11s/epoch - 33ms/step\n",
      "Epoch 22/80\n",
      "327/327 - 11s - loss: 0.0867 - accuracy: 0.6747 - f1: 0.6169 - val_loss: 0.2264 - val_accuracy: 0.5517 - val_f1: 0.5577 - 11s/epoch - 32ms/step\n",
      "Epoch 23/80\n",
      "327/327 - 11s - loss: 0.0801 - accuracy: 0.6793 - f1: 0.6252 - val_loss: 0.2115 - val_accuracy: 0.6000 - val_f1: 0.6203 - 11s/epoch - 34ms/step\n",
      "Epoch 24/80\n",
      "327/327 - 10s - loss: 0.0808 - accuracy: 0.6739 - f1: 0.6226 - val_loss: 0.2454 - val_accuracy: 0.5500 - val_f1: 0.5581 - 10s/epoch - 29ms/step\n",
      "Epoch 25/80\n",
      "327/327 - 10s - loss: 0.0784 - accuracy: 0.6841 - f1: 0.6267 - val_loss: 0.2323 - val_accuracy: 0.5655 - val_f1: 0.5544 - 10s/epoch - 31ms/step\n",
      "Epoch 26/80\n",
      "327/327 - 14s - loss: 0.0757 - accuracy: 0.6933 - f1: 0.6311 - val_loss: 0.2519 - val_accuracy: 0.5138 - val_f1: 0.5621 - 14s/epoch - 42ms/step\n",
      "Epoch 27/80\n",
      "327/327 - 14s - loss: 0.0734 - accuracy: 0.7090 - f1: 0.6468 - val_loss: 0.2163 - val_accuracy: 0.6000 - val_f1: 0.6122 - 14s/epoch - 44ms/step\n",
      "Epoch 28/80\n",
      "327/327 - 14s - loss: 0.0718 - accuracy: 0.6971 - f1: 0.6397 - val_loss: 0.2430 - val_accuracy: 0.5793 - val_f1: 0.5894 - 14s/epoch - 44ms/step\n",
      "Epoch 29/80\n",
      "327/327 - 12s - loss: 0.0708 - accuracy: 0.7174 - f1: 0.6539 - val_loss: 0.2244 - val_accuracy: 0.5931 - val_f1: 0.6207 - 12s/epoch - 37ms/step\n",
      "Epoch 30/80\n",
      "327/327 - 14s - loss: 0.0685 - accuracy: 0.7215 - f1: 0.6564 - val_loss: 0.2344 - val_accuracy: 0.5603 - val_f1: 0.5658 - 14s/epoch - 44ms/step\n",
      "Epoch 31/80\n",
      "327/327 - 15s - loss: 0.0664 - accuracy: 0.7308 - f1: 0.6659 - val_loss: 0.2252 - val_accuracy: 0.5966 - val_f1: 0.5724 - 15s/epoch - 46ms/step\n",
      "Epoch 32/80\n",
      "327/327 - 14s - loss: 0.0673 - accuracy: 0.7262 - f1: 0.6575 - val_loss: 0.2190 - val_accuracy: 0.5724 - val_f1: 0.5799 - 14s/epoch - 44ms/step\n",
      "Epoch 33/80\n",
      "327/327 - 14s - loss: 0.0657 - accuracy: 0.7245 - f1: 0.6595 - val_loss: 0.2108 - val_accuracy: 0.6241 - val_f1: 0.6043 - 14s/epoch - 42ms/step\n",
      "Epoch 34/80\n",
      "327/327 - 15s - loss: 0.0622 - accuracy: 0.7404 - f1: 0.6724 - val_loss: 0.2249 - val_accuracy: 0.5845 - val_f1: 0.5840 - 15s/epoch - 46ms/step\n",
      "Epoch 35/80\n",
      "327/327 - 13s - loss: 0.0615 - accuracy: 0.7423 - f1: 0.6745 - val_loss: 0.2137 - val_accuracy: 0.6190 - val_f1: 0.6101 - 13s/epoch - 41ms/step\n",
      "Epoch 36/80\n",
      "327/327 - 10s - loss: 0.0574 - accuracy: 0.7521 - f1: 0.6864 - val_loss: 0.2076 - val_accuracy: 0.6310 - val_f1: 0.6290 - 10s/epoch - 30ms/step\n",
      "Epoch 37/80\n",
      "327/327 - 10s - loss: 0.0589 - accuracy: 0.7513 - f1: 0.6823 - val_loss: 0.2208 - val_accuracy: 0.5897 - val_f1: 0.6019 - 10s/epoch - 32ms/step\n",
      "Epoch 38/80\n",
      "327/327 - 13s - loss: 0.0555 - accuracy: 0.7686 - f1: 0.6951 - val_loss: 0.2207 - val_accuracy: 0.6190 - val_f1: 0.6254 - 13s/epoch - 38ms/step\n",
      "Epoch 39/80\n",
      "327/327 - 12s - loss: 0.0560 - accuracy: 0.7709 - f1: 0.6974 - val_loss: 0.2339 - val_accuracy: 0.6241 - val_f1: 0.6023 - 12s/epoch - 36ms/step\n",
      "Epoch 40/80\n",
      "327/327 - 12s - loss: 0.0556 - accuracy: 0.7657 - f1: 0.6948 - val_loss: 0.2266 - val_accuracy: 0.6138 - val_f1: 0.6133 - 12s/epoch - 37ms/step\n",
      "Epoch 41/80\n",
      "327/327 - 13s - loss: 0.0536 - accuracy: 0.7860 - f1: 0.7126 - val_loss: 0.2359 - val_accuracy: 0.6034 - val_f1: 0.6011 - 13s/epoch - 40ms/step\n",
      "Epoch 42/80\n",
      "327/327 - 13s - loss: 0.0533 - accuracy: 0.7709 - f1: 0.6937 - val_loss: 0.2501 - val_accuracy: 0.5845 - val_f1: 0.5920 - 13s/epoch - 39ms/step\n",
      "Epoch 43/80\n",
      "327/327 - 12s - loss: 0.0553 - accuracy: 0.7680 - f1: 0.6973 - val_loss: 0.2405 - val_accuracy: 0.6224 - val_f1: 0.6015 - 12s/epoch - 37ms/step\n",
      "Epoch 44/80\n",
      "327/327 - 13s - loss: 0.0521 - accuracy: 0.7824 - f1: 0.7075 - val_loss: 0.2338 - val_accuracy: 0.5810 - val_f1: 0.5868 - 13s/epoch - 38ms/step\n",
      "Epoch 45/80\n",
      "327/327 - 13s - loss: 0.0542 - accuracy: 0.7887 - f1: 0.7101 - val_loss: 0.2377 - val_accuracy: 0.5914 - val_f1: 0.5782 - 13s/epoch - 39ms/step\n",
      "Epoch 46/80\n",
      "327/327 - 12s - loss: 0.0501 - accuracy: 0.7816 - f1: 0.7078 - val_loss: 0.2541 - val_accuracy: 0.5621 - val_f1: 0.5854 - 12s/epoch - 37ms/step\n",
      "Epoch 47/80\n",
      "327/327 - 13s - loss: 0.0483 - accuracy: 0.7966 - f1: 0.7178 - val_loss: 0.2240 - val_accuracy: 0.6034 - val_f1: 0.5965 - 13s/epoch - 40ms/step\n",
      "Epoch 48/80\n",
      "327/327 - 13s - loss: 0.0501 - accuracy: 0.7956 - f1: 0.7175 - val_loss: 0.2574 - val_accuracy: 0.5603 - val_f1: 0.5736 - 13s/epoch - 39ms/step\n",
      "Epoch 49/80\n",
      "327/327 - 12s - loss: 0.0519 - accuracy: 0.7929 - f1: 0.7082 - val_loss: 0.2619 - val_accuracy: 0.5776 - val_f1: 0.5931 - 12s/epoch - 38ms/step\n",
      "Epoch 50/80\n",
      "327/327 - 13s - loss: 0.0467 - accuracy: 0.8069 - f1: 0.7243 - val_loss: 0.2350 - val_accuracy: 0.6155 - val_f1: 0.5959 - 13s/epoch - 39ms/step\n",
      "Epoch 51/80\n",
      "327/327 - 13s - loss: 0.0449 - accuracy: 0.8149 - f1: 0.7353 - val_loss: 0.2576 - val_accuracy: 0.5655 - val_f1: 0.5825 - 13s/epoch - 39ms/step\n",
      "Epoch 52/80\n",
      "327/327 - 12s - loss: 0.0446 - accuracy: 0.8119 - f1: 0.7327 - val_loss: 0.2597 - val_accuracy: 0.5569 - val_f1: 0.5823 - 12s/epoch - 37ms/step\n",
      "Epoch 53/80\n",
      "327/327 - 13s - loss: 0.0475 - accuracy: 0.8042 - f1: 0.7241 - val_loss: 0.2354 - val_accuracy: 0.6017 - val_f1: 0.6205 - 13s/epoch - 39ms/step\n",
      "Epoch 54/80\n",
      "327/327 - 13s - loss: 0.0438 - accuracy: 0.8174 - f1: 0.7383 - val_loss: 0.2482 - val_accuracy: 0.5966 - val_f1: 0.5932 - 13s/epoch - 39ms/step\n",
      "Epoch 55/80\n",
      "327/327 - 12s - loss: 0.0444 - accuracy: 0.8190 - f1: 0.7387 - val_loss: 0.2509 - val_accuracy: 0.5862 - val_f1: 0.6041 - 12s/epoch - 37ms/step\n",
      "Epoch 56/80\n",
      "327/327 - 13s - loss: 0.0440 - accuracy: 0.8192 - f1: 0.7363 - val_loss: 0.2530 - val_accuracy: 0.6000 - val_f1: 0.6037 - 13s/epoch - 40ms/step\n",
      "Epoch 57/80\n",
      "327/327 - 13s - loss: 0.0419 - accuracy: 0.8230 - f1: 0.7392 - val_loss: 0.2513 - val_accuracy: 0.6000 - val_f1: 0.6038 - 13s/epoch - 39ms/step\n",
      "Epoch 58/80\n",
      "327/327 - 12s - loss: 0.0408 - accuracy: 0.8385 - f1: 0.7505 - val_loss: 0.2718 - val_accuracy: 0.5914 - val_f1: 0.6160 - 12s/epoch - 37ms/step\n",
      "Epoch 59/80\n",
      "327/327 - 13s - loss: 0.0412 - accuracy: 0.8341 - f1: 0.7452 - val_loss: 0.2460 - val_accuracy: 0.5845 - val_f1: 0.5832 - 13s/epoch - 39ms/step\n",
      "Epoch 60/80\n",
      "327/327 - 13s - loss: 0.0405 - accuracy: 0.8366 - f1: 0.7480 - val_loss: 0.2755 - val_accuracy: 0.5862 - val_f1: 0.5876 - 13s/epoch - 40ms/step\n",
      "Epoch 61/80\n",
      "327/327 - 12s - loss: 0.0393 - accuracy: 0.8458 - f1: 0.7564 - val_loss: 0.2627 - val_accuracy: 0.6690 - val_f1: 0.6259 - 12s/epoch - 37ms/step\n",
      "Epoch 62/80\n",
      "327/327 - 13s - loss: 0.0394 - accuracy: 0.8364 - f1: 0.7519 - val_loss: 0.2576 - val_accuracy: 0.6690 - val_f1: 0.6300 - 13s/epoch - 40ms/step\n",
      "Epoch 63/80\n",
      "327/327 - 13s - loss: 0.0383 - accuracy: 0.8435 - f1: 0.7570 - val_loss: 0.2553 - val_accuracy: 0.6259 - val_f1: 0.6148 - 13s/epoch - 40ms/step\n",
      "Epoch 64/80\n",
      "327/327 - 17s - loss: 0.0357 - accuracy: 0.8492 - f1: 0.7607 - val_loss: 0.2533 - val_accuracy: 0.6086 - val_f1: 0.6182 - 17s/epoch - 51ms/step\n",
      "Epoch 65/80\n",
      "327/327 - 16s - loss: 0.0387 - accuracy: 0.8421 - f1: 0.7537 - val_loss: 0.3106 - val_accuracy: 0.5328 - val_f1: 0.5689 - 16s/epoch - 50ms/step\n",
      "Epoch 66/80\n",
      "327/327 - 14s - loss: 0.0392 - accuracy: 0.8448 - f1: 0.7568 - val_loss: 0.2842 - val_accuracy: 0.5845 - val_f1: 0.6155 - 14s/epoch - 43ms/step\n",
      "Epoch 67/80\n",
      "327/327 - 17s - loss: 0.0361 - accuracy: 0.8596 - f1: 0.7613 - val_loss: 0.3066 - val_accuracy: 0.5448 - val_f1: 0.5709 - 17s/epoch - 51ms/step\n",
      "Epoch 68/80\n",
      "327/327 - 15s - loss: 0.0368 - accuracy: 0.8525 - f1: 0.7589 - val_loss: 0.2600 - val_accuracy: 0.6345 - val_f1: 0.6225 - 15s/epoch - 46ms/step\n",
      "Epoch 69/80\n",
      "327/327 - 13s - loss: 0.0353 - accuracy: 0.8630 - f1: 0.7688 - val_loss: 0.2854 - val_accuracy: 0.5672 - val_f1: 0.5771 - 13s/epoch - 40ms/step\n",
      "Epoch 70/80\n",
      "327/327 - 14s - loss: 0.0356 - accuracy: 0.8646 - f1: 0.7670 - val_loss: 0.2669 - val_accuracy: 0.6069 - val_f1: 0.5951 - 14s/epoch - 42ms/step\n",
      "Epoch 71/80\n",
      "327/327 - 14s - loss: 0.0384 - accuracy: 0.8523 - f1: 0.7571 - val_loss: 0.2930 - val_accuracy: 0.5845 - val_f1: 0.6055 - 14s/epoch - 44ms/step\n",
      "Epoch 72/80\n",
      "327/327 - 13s - loss: 0.0402 - accuracy: 0.8408 - f1: 0.7521 - val_loss: 0.2674 - val_accuracy: 0.6241 - val_f1: 0.6035 - 13s/epoch - 40ms/step\n",
      "Epoch 73/80\n",
      "327/327 - 13s - loss: 0.0354 - accuracy: 0.8586 - f1: 0.7648 - val_loss: 0.2840 - val_accuracy: 0.6603 - val_f1: 0.6221 - 13s/epoch - 41ms/step\n",
      "Epoch 74/80\n",
      "327/327 - 14s - loss: 0.0383 - accuracy: 0.8544 - f1: 0.7608 - val_loss: 0.3569 - val_accuracy: 0.5190 - val_f1: 0.5627 - 14s/epoch - 43ms/step\n",
      "Epoch 75/80\n",
      "327/327 - 10s - loss: 0.0354 - accuracy: 0.8596 - f1: 0.7627 - val_loss: 0.2956 - val_accuracy: 0.6052 - val_f1: 0.5884 - 10s/epoch - 30ms/step\n",
      "Epoch 76/80\n",
      "327/327 - 11s - loss: 0.0344 - accuracy: 0.8630 - f1: 0.7665 - val_loss: 0.2840 - val_accuracy: 0.6103 - val_f1: 0.5918 - 11s/epoch - 33ms/step\n",
      "Epoch 77/80\n",
      "327/327 - 12s - loss: 0.0326 - accuracy: 0.8741 - f1: 0.7775 - val_loss: 0.2941 - val_accuracy: 0.6500 - val_f1: 0.6193 - 12s/epoch - 37ms/step\n",
      "Epoch 78/80\n",
      "327/327 - 13s - loss: 0.0309 - accuracy: 0.8755 - f1: 0.7766 - val_loss: 0.3002 - val_accuracy: 0.6121 - val_f1: 0.6057 - 13s/epoch - 39ms/step\n",
      "Epoch 79/80\n",
      "327/327 - 14s - loss: 0.0342 - accuracy: 0.8720 - f1: 0.7714 - val_loss: 0.3081 - val_accuracy: 0.6000 - val_f1: 0.5792 - 14s/epoch - 42ms/step\n",
      "Epoch 80/80\n",
      "327/327 - 13s - loss: 0.0340 - accuracy: 0.8738 - f1: 0.7691 - val_loss: 0.3055 - val_accuracy: 0.5983 - val_f1: 0.5956 - 13s/epoch - 40ms/step\n",
      "19/19 [==============================] - 3s 33ms/step\n",
      "19/19 [==============================] - 1s 15ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.72      0.70      0.71       310\n",
      "           D       0.53      0.58      0.56       167\n",
      "           G       0.58      0.54      0.56        26\n",
      "           C       0.81      0.90      0.85        29\n",
      "           A       0.87      0.54      0.67        24\n",
      "           M       0.88      0.92      0.90        24\n",
      "\n",
      "    accuracy                           0.67       580\n",
      "   macro avg       0.73      0.70      0.71       580\n",
      "weighted avg       0.67      0.67      0.67       580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MODELO 4 CON CUTMIX - Dataset DESBALANCEADO\n",
    "# ============================================\n",
    "\n",
    "import os, sys, cv2, numpy as np, pandas as pd, torch, argparse\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_recall_curve, classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.utils import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# CONFIGURACIÓN\n",
    "IMG_SIZE     = 224\n",
    "BATCH_SIZE   = 16\n",
    "EPOCHS       = 80\n",
    "SMOTE_K      = 5\n",
    "ENSEMBLE_W   = 0.7\n",
    "LABEL_SMOOTH = 0.1\n",
    "LABELS       = ['N', 'D', 'G', 'C', 'A', 'M']\n",
    "THRESH       = np.ones(len(LABELS)) * 0.5\n",
    "\n",
    "# CUTMIX\n",
    "def cutmix(x, y, alpha=1.0):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = x.shape[0]\n",
    "    idx = np.random.permutation(batch_size)\n",
    "    cut_ratio = np.sqrt(1. - lam)\n",
    "    feat_len = x.shape[1]\n",
    "    cut_len = int(feat_len * cut_ratio)\n",
    "    start = np.random.randint(0, feat_len - cut_len)\n",
    "    end = start + cut_len\n",
    "    x_cutmix = x.copy()\n",
    "    x_cutmix[:, start:end] = x[idx, start:end]\n",
    "    y_cutmix = lam * y + (1 - lam) * y[idx]\n",
    "    return x_cutmix, y_cutmix\n",
    "\n",
    "# CARGA DE CARACTERÍSTICAS\n",
    "X1_tr = np.load(\"C:/Users/34629/Downloads/X_rf_train_DES.npy\")\n",
    "X2_tr = np.load(\"C:/Users/34629/Downloads/X_eff_train_DES.npy\")\n",
    "y_tr  = np.load(\"C:/Users/34629/Downloads/y_train_DES.npy\")\n",
    "X1_vl = np.load(\"C:/Users/34629/Downloads/X_rf_val_DES.npy\")\n",
    "X2_vl = np.load(\"C:/Users/34629/Downloads/X_eff_val_DES.npy\")\n",
    "y_vl  = np.load(\"C:/Users/34629/Downloads/y_val_DES.npy\")\n",
    "\n",
    "y_tr_cat = to_categorical(y_tr, num_classes=len(LABELS))\n",
    "y_vl_cat = to_categorical(y_vl, num_classes=len(LABELS))\n",
    "\n",
    "# SMOTE\n",
    "sm = SMOTE(k_neighbors=SMOTE_K, random_state=42)\n",
    "X1_tr, yidx = sm.fit_resample(X1_tr, y_tr)\n",
    "y_tr_cat_rf = to_categorical(yidx, num_classes=len(LABELS))\n",
    "\n",
    "# Label smoothing\n",
    "y_tr_cat_rf = y_tr_cat_rf * (1 - LABEL_SMOOTH) + LABEL_SMOOTH / len(LABELS)\n",
    "y_tr_cat_eff = y_tr_cat * (1 - LABEL_SMOOTH) + LABEL_SMOOTH / len(LABELS)\n",
    "\n",
    "# CUTMIX\n",
    "X1_tr, y_tr_cat_rf = cutmix(X1_tr, y_tr_cat_rf, alpha=1.0)\n",
    "\n",
    "# Pesos de clase\n",
    "cw_rf = compute_class_weight('balanced', classes=np.arange(len(LABELS)), y=np.argmax(y_tr_cat_rf, axis=1))\n",
    "cw_eff = compute_class_weight('balanced', classes=np.arange(len(LABELS)), y=np.argmax(y_tr_cat_eff, axis=1))\n",
    "cw_rf = {i: w for i, w in enumerate(cw_rf)}\n",
    "cw_eff = {i: w for i, w in enumerate(cw_eff)}\n",
    "\n",
    "# MODELOS\n",
    "inp1 = Input((X1_tr.shape[1],))\n",
    "x = Dense(1024)(inp1); x = BatchNormalization()(x); x = LeakyReLU(0.1)(x)\n",
    "x = Dropout(0.5)(x); x = Dense(512)(x); x = BatchNormalization()(x); x = LeakyReLU(0.1)(x)\n",
    "x = Dropout(0.4)(x); x = Dense(256)(x); x = BatchNormalization()(x); x = LeakyReLU(0.1)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "out1 = Dense(len(LABELS), activation='softmax')(x)\n",
    "m1 = Model(inp1, out1)\n",
    "\n",
    "inp2 = Input((X2_tr.shape[1],))\n",
    "y_ = Dense(512)(inp2); y_ = BatchNormalization()(y_); y_ = LeakyReLU(0.1)(y_)\n",
    "y_ = Dropout(0.4)(y_); out2 = Dense(len(LABELS), activation='softmax')(y_)\n",
    "m2 = Model(inp2, out2)\n",
    "\n",
    "loss_fn = tfa.losses.SigmoidFocalCrossEntropy(from_logits=False)\n",
    "\n",
    "for model, cw in [(m1, cw_rf), (m2, cw_eff)]:\n",
    "    model.compile(optimizer=Adam(1e-4), loss=loss_fn,\n",
    "                  metrics=['accuracy', tfa.metrics.F1Score(len(LABELS), 'macro', name='f1')])\n",
    "\n",
    "# ENTRENAMIENTO\n",
    "m1.fit(X1_tr, y_tr_cat_rf, validation_data=(X1_vl, y_vl_cat), epochs=EPOCHS,\n",
    "       batch_size=BATCH_SIZE, class_weight=cw_rf, verbose=2)\n",
    "m2.fit(X2_tr, y_tr_cat_eff, validation_data=(X2_vl, y_vl_cat), epochs=EPOCHS,\n",
    "       batch_size=BATCH_SIZE, class_weight=cw_eff, verbose=2)\n",
    "\n",
    "# ENSEMBLE\n",
    "p1 = m1.predict(X1_vl)\n",
    "p2 = m2.predict(X2_vl)\n",
    "probs = ENSEMBLE_W * p1 + (1 - ENSEMBLE_W) * p2\n",
    "\n",
    "for i in range(len(LABELS)):\n",
    "    prec, rec, thr = precision_recall_curve((y_vl == i).astype(int), probs[:, i])\n",
    "    F = 2 * prec * rec / (prec + rec + 1e-8)\n",
    "    THRESH[i] = thr[np.nanargmax(F)]\n",
    "\n",
    "y_pred = []\n",
    "for row in probs:\n",
    "    sel = np.where(row >= THRESH)[0]\n",
    "    if len(sel) == 1: y_pred.append(sel[0])\n",
    "    elif len(sel) > 1: y_pred.append(sel[np.argmax(row[sel])])\n",
    "    else: y_pred.append(np.argmax(row))\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# MÉTRICAS\n",
    "print(classification_report(y_vl, y_pred, target_names=LABELS))\n",
    "cm = confusion_matrix(y_vl, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=LABELS, yticklabels=LABELS)\n",
    "plt.title(\"Matriz Confusión - Modelo 4 DES\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"matriz_confusion_modelo4_DES.png\")\n",
    "plt.close()\n",
    "\n",
    "# ROC\n",
    "from sklearn.preprocessing import label_binarize\n",
    "y_vl_bin = label_binarize(y_vl, classes=np.arange(len(LABELS)))\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(len(LABELS)):\n",
    "    fpr, tpr, _ = roc_curve(y_vl_bin[:, i], probs[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f\"{LABELS[i]} (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.legend(); plt.title(\"Curvas ROC - Modelo 4 DES\"); plt.tight_layout()\n",
    "plt.savefig(\"curva_ROC_modelo4_DES.png\")\n",
    "plt.close()\n",
    "\n",
    "# GRAD-CAM\n",
    "sys.path.append(r\"C:/Users/34629/Downloads/RETFound_MAE\")\n",
    "from models_vit import RETFound_mae\n",
    "from util.pos_embed import interpolate_pos_embed\n",
    "\n",
    "def generar_gradcam(img_path, nombre_archivo):\n",
    "    model = RETFound_mae(global_pool=False, img_size=IMG_SIZE)\n",
    "    ckpt = torch.load(\"C:/Users/34629/Downloads/RETFound_MAE/RETFound_cfp_weights.pth\", map_location='cpu')\n",
    "    sd = ckpt['model']; sd.pop('head.weight', None); sd.pop('head.bias', None)\n",
    "    interpolate_pos_embed(model, sd); model.load_state_dict(sd, strict=False)\n",
    "    model.eval()\n",
    "    activations = {}\n",
    "    model.blocks[11].register_forward_hook(lambda m, i, o: activations.update({'value': o}))\n",
    "    img = Image.open(img_path).convert('RGB').resize((IMG_SIZE, IMG_SIZE))\n",
    "    x = transforms.ToTensor()(img).unsqueeze(0)\n",
    "    with torch.no_grad(): model(x)\n",
    "    cam = activations['value'].squeeze(0).numpy()[1:].mean(axis=1).reshape(14, 14)\n",
    "    cam = cv2.resize((cam - cam.min()) / (cam.max() - cam.min()), (IMG_SIZE, IMG_SIZE))\n",
    "    cam = np.uint8(255 * cam); cam_color = cv2.applyColorMap(cam, cv2.COLORMAP_JET)\n",
    "    superpuesta = 0.4 * np.array(img) + 0.6 * cam_color\n",
    "    cv2.imwrite(nombre_archivo, cv2.cvtColor(np.uint8(superpuesta), cv2.COLOR_RGB2BGR))\n",
    "\n",
    "# GENERAR EJEMPLOS\n",
    "val_df = pd.read_csv(\"C:/Users/34629/TFG/val_DES.csv\")\n",
    "paths = val_df['Image_Path'].tolist()\n",
    "df_res = pd.DataFrame({'img': paths, 'true': y_vl, 'pred': y_pred})\n",
    "df_res['correct'] = df_res['true'] == df_res['pred']\n",
    "bien = df_res[df_res['correct']].iloc[0]\n",
    "mal  = df_res[~df_res['correct']].iloc[0]\n",
    "generar_gradcam(bien['img'], f\"gradcam_modelo4_DES_bien_{LABELS[bien['true']]}.png\")\n",
    "generar_gradcam(mal['img'],  f\"gradcam_modelo4_DES_mal_{LABELS[mal['true']]}_pred{LABELS[mal['pred']]}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc3a959f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Ejemplo de matriz de confusión real (de tu imagen)\n",
    "conf_matrix = np.array([\n",
    "    [216, 77, 9, 6, 1, 1],\n",
    "    [66, 97, 1, 0, 1, 2],\n",
    "    [9, 3, 14, 0, 0, 0],\n",
    "    [3, 0, 0, 26, 0, 0],\n",
    "    [6, 5, 0, 0, 13, 0],\n",
    "    [2, 0, 0, 0, 0, 22]\n",
    "])\n",
    "\n",
    "# Nombres de clases\n",
    "labels = ['N', 'D', 'G', 'C', 'A', 'M']\n",
    "\n",
    "# Normalizar por fila (suma por cada clase real)\n",
    "row_sums = conf_matrix.sum(axis=1, keepdims=True)\n",
    "conf_matrix_normalized = conf_matrix / row_sums\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
    "            xticklabels=labels, yticklabels=labels, cbar_kws={'label': 'Proporción'})\n",
    "plt.title(\"Matriz de Confusión del Modelo 4 desequilibrado\")\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Etiqueta verdadera\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
